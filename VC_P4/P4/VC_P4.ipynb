{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos preentrenados, visualizando con las utilidades de ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo\n",
    "#model = YOLO('yolo11n.pt') #Contenedores\n",
    "#model = YOLO('yolo11n-seg.pt') #M치scaras\n",
    "model = YOLO('yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un v칤deo \n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "results = model(filename, show=True)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde c치mara, detecci칩n con yolo11, modelo nano. Visualizaci칩n propia con OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo, descarga en disco si no est치 presente en la carpeta\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen v치lida\n",
    "    if ret:  \n",
    "        # Detecta en la imagen\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detecci칩n\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador num칠rico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimiento. Requiere instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Carga del modelo, descarga en disco si no est치 presente en la carpeta\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\"]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "track_history = defaultdict(lambda: [])\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen v치lida\n",
    "    if ret:  \n",
    "        # Seguimiento, con persistencia entre fotogramas\n",
    "        results = model.track(img, persist=True, classes = [0,1,2])\n",
    "\n",
    "        if 0:\n",
    "            if results is not None:\n",
    "                print(results[0])\n",
    "                boxes = results[0].boxes.xywh.cpu()\n",
    "                track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "                annotated_frame = results[0].plot()\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x, y, w, h = box\n",
    "                    track = track_history[track_id]\n",
    "                    track.append((float(x), float(y)))\n",
    "                    if len(track) > 30:\n",
    "                        track.pop(0)\n",
    "                    points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "                cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "        \n",
    "\n",
    "        \n",
    "        # Para cada detecci칩n\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "                #Etiqueta de seguimiento\n",
    "                if box.id is not None:\n",
    "                    track_id = str(int(box.id[0].tolist()))\n",
    "                else:\n",
    "                    track_id = ''\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador num칠rico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, track_id + ' ' + classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Dispositivo: CUDA\n",
      "[INFO] GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "[INFO] Procesando 2832 frames...\n",
      "\n",
      "[INFO] Procesados 100/2832 frames (3%)\n",
      "[INFO] Procesados 200/2832 frames (7%)\n",
      "[INFO] Procesados 300/2832 frames (10%)\n",
      "[INFO] Procesados 400/2832 frames (14%)\n",
      "[INFO] Procesados 500/2832 frames (17%)\n",
      "[INFO] Procesados 600/2832 frames (21%)\n",
      "[INFO] Procesados 700/2832 frames (24%)\n",
      "[INFO] Procesados 800/2832 frames (28%)\n",
      "[INFO] Procesados 900/2832 frames (31%)\n",
      "[INFO] Procesados 1000/2832 frames (35%)\n",
      "[INFO] Procesados 1100/2832 frames (38%)\n",
      "[INFO] Procesados 1200/2832 frames (42%)\n",
      "[INFO] Procesados 1300/2832 frames (45%)\n",
      "[INFO] Procesados 1400/2832 frames (49%)\n",
      "[INFO] Procesados 1500/2832 frames (52%)\n",
      "[INFO] Procesados 1600/2832 frames (56%)\n",
      "[INFO] Procesados 1700/2832 frames (60%)\n",
      "[INFO] Procesados 1800/2832 frames (63%)\n",
      "[INFO] Procesados 1900/2832 frames (67%)\n",
      "[INFO] Procesados 2000/2832 frames (70%)\n",
      "[INFO] Procesados 2100/2832 frames (74%)\n",
      "[INFO] Procesados 2200/2832 frames (77%)\n",
      "[INFO] Procesados 2300/2832 frames (81%)\n",
      "[INFO] Procesados 2400/2832 frames (84%)\n",
      "[INFO] Procesados 2500/2832 frames (88%)\n",
      "[INFO] Procesados 2600/2832 frames (91%)\n",
      "[INFO] Procesados 2700/2832 frames (95%)\n",
      "[INFO] Procesados 2800/2832 frames (98%)\n",
      "\n",
      "========== RESULTADOS ==========\n",
      "bicycle: 4 detectados en total\n",
      "car: 249 detectados en total\n",
      "motorbike: 9 detectados en total\n",
      "person: 49 detectados en total\n",
      "truck: 9 detectados en total\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PIPELINE GPU OPTIMIZADO - ANONIMIZACI칍N SIN OCR (MEJOR DETECCI칍N DE MATR칈CULAS)\n",
    "Autor: Corazoncito de Melocot칩n 游눝\n",
    "\n",
    "Caracter칤sticas:\n",
    "- YOLO11n para detecci칩n general + YOLO especializado para matr칤culas\n",
    "- Blur estable y centrado\n",
    "- IDs visibles en v칤deo\n",
    "- Detecci칩n m치s robusta de matr칤culas (sin OCR)\n",
    "- GPU optimizada, m치ximo rendimiento\n",
    "\"\"\"\n",
    "\n",
    "# ========================= CONFIG =========================\n",
    "VIDEO_IN_PATH = \"C0142.MP4\"\n",
    "VIDEO_OUT_PATH = \"outputs/salida_anonimizada.mp4\"\n",
    "CSV_OUT_PATH = \"outputs/detecciones.csv\"\n",
    "\n",
    "GENERAL_MODEL = \"yolo11n.pt\"\n",
    "PLATE_MODEL = \"best.pt\"\n",
    "\n",
    "CONF_THRESHOLD = 0.25\n",
    "BLUR_INTENSITY = 61\n",
    "MOVEMENT_THRESHOLD = 50\n",
    "# ============================================================\n",
    "\n",
    "import os, csv, cv2, torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "# GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"\\n[INFO] Dispositivo: {device.upper()}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"[INFO] GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# Modelos\n",
    "model_general = YOLO(GENERAL_MODEL).to(device)\n",
    "model_plate = YOLO(PLATE_MODEL).to(device)\n",
    "\n",
    "# Clases que nos interesan\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\"]\n",
    "VEHICLE_CLASSES = {\"car\", \"bus\", \"truck\", \"motorbike\", \"bicycle\"}\n",
    "\n",
    "# ====== FUNCIONES ======\n",
    "def blur_region(img, x1, y1, x2, y2, intensity=BLUR_INTENSITY):\n",
    "    \"\"\"Aplica blur controlando l칤mites\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1, x2, y2 = map(int, [max(0, x1), max(0, y1), min(w, x2), min(h, y2)])\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return img\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    k = intensity if (x2 - x1) > 30 else 15\n",
    "    k = k if k % 2 == 1 else k + 1\n",
    "    blurred = cv2.GaussianBlur(roi, (k, k), 0)\n",
    "    img[y1:y2, x1:x2] = blurred\n",
    "    return img\n",
    "\n",
    "def smooth_coords(prev, new, alpha=0.5):\n",
    "    \"\"\"Suavizado exponencial de coordenadas\"\"\"\n",
    "    if prev is None:\n",
    "        return new\n",
    "    return tuple(int(p * (1 - alpha) + n * alpha) for p, n in zip(prev, new))\n",
    "\n",
    "# ====== VIDEO ======\n",
    "cap = cv2.VideoCapture(VIDEO_IN_PATH)\n",
    "width, height = int(cap.get(3)), int(cap.get(4))\n",
    "fps = cap.get(5) or 25\n",
    "total_frames = int(cap.get(7))\n",
    "\n",
    "out = cv2.VideoWriter(VIDEO_OUT_PATH, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
    "\n",
    "# ====== CSV ======\n",
    "csv_file = open(CSV_OUT_PATH, \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "writer = csv.writer(csv_file)\n",
    "writer.writerow([\"frame\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "                 \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "                 \"matricula_detectada\", \"conf_matricula\",\n",
    "                 \"mx1\", \"my1\", \"mx2\", \"my2\"])\n",
    "\n",
    "# ====== TRACKING ======\n",
    "results_stream = model_general.track(\n",
    "    source=VIDEO_IN_PATH,\n",
    "    tracker=\"botsort.yaml\",\n",
    "    stream=True,\n",
    "    device=device,\n",
    "    classes=[0, 1, 2, 3, 5, 7],  # Solo personas, bicis, coches, motos, bus, cami칩n\n",
    "    verbose=False  # Desactiva los prints de YOLO\n",
    ")\n",
    "\n",
    "total_detections = defaultdict(set)\n",
    "plate_tracker = {}\n",
    "frame_id = 0\n",
    "\n",
    "print(f\"\\n[INFO] Procesando {total_frames} frames...\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# LOOP PRINCIPAL\n",
    "# ============================================================\n",
    "for res in results_stream:\n",
    "    frame_id += 1\n",
    "    frame = res.orig_img.copy()\n",
    "    boxes = res.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        cls_id = int(box.cls)\n",
    "        if cls_id >= len(classNames):\n",
    "            continue\n",
    "        label = classNames[cls_id]\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "        conf = float(box.conf)\n",
    "        track_id = int(box.id) if box.id is not None else -1\n",
    "\n",
    "        # --- Conteo acumulado ---\n",
    "        if track_id != -1:\n",
    "            total_detections[label].add(track_id)\n",
    "\n",
    "        # ===== PERSONAS =====\n",
    "        if label == \"person\":\n",
    "            frame = blur_region(frame, x1, y1, x2, y2)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"Person {track_id}\", (x1, y1 - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "            continue\n",
    "\n",
    "        # ===== VEH칈CULOS =====\n",
    "        if label in VEHICLE_CLASSES:\n",
    "            mx1 = my1 = mx2 = my2 = -1\n",
    "            plate_conf = 0.0\n",
    "            plate_found = False\n",
    "\n",
    "            crop = frame[y1:y2, x1:x2]\n",
    "            if crop.size > 0:\n",
    "                lp_res = model_plate.predict(crop, conf=CONF_THRESHOLD, device=device, verbose=False)\n",
    "                if len(lp_res[0].boxes) > 0:\n",
    "                    # --- Usa la de mayor confianza ---\n",
    "                    best_box = max(lp_res[0].boxes, key=lambda b: b.conf)\n",
    "                    lx1, ly1, lx2, ly2 = map(int, best_box.xyxy[0].cpu().numpy())\n",
    "                    mx1, my1, mx2, my2 = x1 + lx1, y1 + ly1, x1 + lx2, y1 + ly2\n",
    "                    plate_conf = float(best_box.conf)\n",
    "                    plate_found = True\n",
    "\n",
    "            # --- Suavizado de coordenadas ---\n",
    "            if track_id != -1:\n",
    "                prev = plate_tracker.get(track_id, {}).get(\"pos\")\n",
    "                new_coords = (mx1, my1, mx2, my2) if plate_found else prev\n",
    "                smoothed = smooth_coords(prev, new_coords) if new_coords else None\n",
    "                if smoothed:\n",
    "                    mx1, my1, mx2, my2 = smoothed\n",
    "                    plate_tracker[track_id] = {\"pos\": smoothed, \"conf\": plate_conf}\n",
    "\n",
    "            # --- Blur de matr칤cula ---\n",
    "            if track_id in plate_tracker and plate_tracker[track_id].get(\"pos\"):\n",
    "                mx1, my1, mx2, my2 = plate_tracker[track_id][\"pos\"]\n",
    "                frame = blur_region(frame, mx1, my1, mx2, my2)\n",
    "                cv2.rectangle(frame, (mx1, my1), (mx2, my2), (0, 255, 0), 2)\n",
    "\n",
    "            # --- Caja del veh칤culo ---\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 128, 255), 2)\n",
    "            cv2.putText(frame, f\"{label} {track_id}\", (x1, y1 - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 128, 255), 2)\n",
    "\n",
    "            writer.writerow([frame_id, label, round(conf, 3), track_id,\n",
    "                             x1, y1, x2, y2, int(plate_found), round(plate_conf, 3),\n",
    "                             mx1, my1, mx2, my2])\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    # Imprimir progreso cada 100 frames\n",
    "    if frame_id % 100 == 0:\n",
    "        print(f\"[INFO] Procesados {frame_id}/{total_frames} frames ({frame_id*100//total_frames}%)\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "csv_file.close()\n",
    "\n",
    "# ============================================================\n",
    "# RESULTADOS\n",
    "# ============================================================\n",
    "print(\"\\n========== RESULTADOS ==========\")\n",
    "for cls, ids in sorted(total_detections.items()):\n",
    "    print(f\"{cls}: {len(ids)} detectados en total\")\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Dispositivo: CUDA\n",
      "[INFO] GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "[INFO] Inicializando EasyOCR...\n",
      "[INFO] EasyOCR listo\n",
      "\n",
      "[INFO] Procesando 2832 frames...\n",
      "\n",
      "[INFO] Procesados 100/2832 frames (3%)\n",
      "[INFO] Procesados 200/2832 frames (7%)\n",
      "[INFO] Procesados 300/2832 frames (10%)\n",
      "[INFO] Procesados 400/2832 frames (14%)\n",
      "[INFO] Procesados 500/2832 frames (17%)\n",
      "[INFO] Procesados 600/2832 frames (21%)\n",
      "[INFO] Procesados 700/2832 frames (24%)\n",
      "[INFO] Procesados 800/2832 frames (28%)\n",
      "[INFO] Procesados 900/2832 frames (31%)\n",
      "[INFO] Procesados 1000/2832 frames (35%)\n",
      "[INFO] Procesados 1100/2832 frames (38%)\n",
      "[INFO] Procesados 1200/2832 frames (42%)\n",
      "[INFO] Procesados 1300/2832 frames (45%)\n",
      "[INFO] Procesados 1400/2832 frames (49%)\n",
      "[INFO] Procesados 1500/2832 frames (52%)\n",
      "[INFO] Procesados 1600/2832 frames (56%)\n",
      "[INFO] Procesados 1700/2832 frames (60%)\n",
      "[INFO] Procesados 1800/2832 frames (63%)\n",
      "[INFO] Procesados 1900/2832 frames (67%)\n",
      "[INFO] Procesados 2000/2832 frames (70%)\n",
      "[INFO] Procesados 2100/2832 frames (74%)\n",
      "[INFO] Procesados 2200/2832 frames (77%)\n",
      "[INFO] Procesados 2300/2832 frames (81%)\n",
      "[INFO] Procesados 2400/2832 frames (84%)\n",
      "[INFO] Procesados 2500/2832 frames (88%)\n",
      "[INFO] Procesados 2600/2832 frames (91%)\n",
      "[INFO] Procesados 2700/2832 frames (95%)\n",
      "[INFO] Procesados 2800/2832 frames (98%)\n",
      "\n",
      "========== RESULTADOS ==========\n",
      "bicycle: 4 detectados en total\n",
      "car: 249 detectados en total\n",
      "motorbike: 9 detectados en total\n",
      "person: 49 detectados en total\n",
      "truck: 9 detectados en total\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PIPELINE GPU OPTIMIZADO - ANONIMIZACI칍N CON DETECCI칍N DUAL DE MATR칈CULAS\n",
    "Autor: Corazoncito de Melocot칩n 游눝\n",
    "\n",
    "Caracter칤sticas:\n",
    "- YOLO11n para detecci칩n general + YOLO especializado para matr칤culas\n",
    "- EasyOCR para detectar regi칩n de matr칤cula (sin leer texto)\n",
    "- Blur estable y centrado\n",
    "- IDs visibles en v칤deo\n",
    "- Detecci칩n m치s robusta combinando YOLO + EasyOCR\n",
    "- GPU optimizada, m치ximo rendimiento\n",
    "\"\"\"\n",
    "\n",
    "# ========================= CONFIG =========================\n",
    "VIDEO_IN_PATH = \"C0142.MP4\"\n",
    "VIDEO_OUT_PATH = \"outputs/salida_anonimizada.mp4\"\n",
    "CSV_OUT_PATH = \"outputs/detecciones.csv\"\n",
    "\n",
    "GENERAL_MODEL = \"yolo11n.pt\"\n",
    "PLATE_MODEL = \"best.pt\"\n",
    "\n",
    "CONF_THRESHOLD = 0.25\n",
    "BLUR_INTENSITY = 61\n",
    "USE_EASYOCR = True  # Activar/desactivar EasyOCR como detector adicional\n",
    "# ============================================================\n",
    "\n",
    "import os, csv, cv2, torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import easyocr\n",
    "\n",
    "# GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"\\n[INFO] Dispositivo: {device.upper()}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"[INFO] GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# Modelos\n",
    "model_general = YOLO(GENERAL_MODEL).to(device)\n",
    "model_plate = YOLO(PLATE_MODEL).to(device)\n",
    "\n",
    "# EasyOCR (solo para detectar regi칩n, no leer)\n",
    "if USE_EASYOCR:\n",
    "    print(\"[INFO] Inicializando EasyOCR...\")\n",
    "    reader = easyocr.Reader(['en'], gpu=(device == 'cuda'), verbose=False)\n",
    "    print(\"[INFO] EasyOCR listo\")\n",
    "\n",
    "# Clases que nos interesan\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\"]\n",
    "VEHICLE_CLASSES = {\"car\", \"bus\", \"truck\", \"motorbike\", \"bicycle\"}\n",
    "\n",
    "# ====== FUNCIONES ======\n",
    "def blur_region(img, x1, y1, x2, y2, intensity=BLUR_INTENSITY):\n",
    "    \"\"\"Aplica blur controlando l칤mites\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1, x2, y2 = map(int, [max(0, x1), max(0, y1), min(w, x2), min(h, y2)])\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return img\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    k = intensity if (x2 - x1) > 30 else 15\n",
    "    k = k if k % 2 == 1 else k + 1\n",
    "    blurred = cv2.GaussianBlur(roi, (k, k), 0)\n",
    "    img[y1:y2, x1:x2] = blurred\n",
    "    return img\n",
    "\n",
    "def smooth_coords(prev, new, alpha=0.5):\n",
    "    \"\"\"Suavizado exponencial de coordenadas\"\"\"\n",
    "    if prev is None:\n",
    "        return new\n",
    "    return tuple(int(p * (1 - alpha) + n * alpha) for p, n in zip(prev, new))\n",
    "\n",
    "def detect_plate_with_ocr(crop):\n",
    "    \"\"\"Detecta regi칩n de matr칤cula usando EasyOCR (sin leer)\"\"\"\n",
    "    try:\n",
    "        results = reader.readtext(crop, paragraph=False)\n",
    "        if results:\n",
    "            # Buscar el texto m치s parecido a una matr칤cula (alfanum칠rico)\n",
    "            for (bbox, text, conf) in results:\n",
    "                # Solo nos interesan detecciones con confianza razonable\n",
    "                if conf > 0.3 and any(c.isalnum() for c in text):\n",
    "                    # bbox es [[x1,y1], [x2,y1], [x2,y2], [x1,y2]]\n",
    "                    pts = np.array(bbox, dtype=np.int32)\n",
    "                    x1 = int(pts[:, 0].min())\n",
    "                    y1 = int(pts[:, 1].min())\n",
    "                    x2 = int(pts[:, 0].max())\n",
    "                    y2 = int(pts[:, 1].max())\n",
    "                    return (x1, y1, x2, y2, conf)\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def merge_detections(yolo_box, ocr_box):\n",
    "    \"\"\"Combina detecciones de YOLO y OCR para obtener mejor regi칩n\"\"\"\n",
    "    if yolo_box is None and ocr_box is None:\n",
    "        return None\n",
    "    if yolo_box is None:\n",
    "        return ocr_box\n",
    "    if ocr_box is None:\n",
    "        return yolo_box\n",
    "    \n",
    "    # Usar la detecci칩n con mayor confianza o fusionar\n",
    "    yx1, yy1, yx2, yy2, yconf = yolo_box\n",
    "    ox1, oy1, ox2, oy2, oconf = ocr_box\n",
    "    \n",
    "    # Si las cajas se solapan, usar la de mayor confianza\n",
    "    if yconf > oconf:\n",
    "        return yolo_box\n",
    "    else:\n",
    "        return ocr_box\n",
    "\n",
    "# ====== VIDEO ======\n",
    "cap = cv2.VideoCapture(VIDEO_IN_PATH)\n",
    "width, height = int(cap.get(3)), int(cap.get(4))\n",
    "fps = cap.get(5) or 25\n",
    "total_frames = int(cap.get(7))\n",
    "\n",
    "out = cv2.VideoWriter(VIDEO_OUT_PATH, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
    "\n",
    "# ====== CSV ======\n",
    "csv_file = open(CSV_OUT_PATH, \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "writer = csv.writer(csv_file)\n",
    "writer.writerow([\"frame\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "                 \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "                 \"matricula_detectada\", \"conf_matricula\", \"metodo_deteccion\",\n",
    "                 \"mx1\", \"my1\", \"mx2\", \"my2\"])\n",
    "\n",
    "# ====== TRACKING ======\n",
    "results_stream = model_general.track(\n",
    "    source=VIDEO_IN_PATH,\n",
    "    tracker=\"botsort.yaml\",\n",
    "    stream=True,\n",
    "    device=device,\n",
    "    classes=[0, 1, 2, 3, 5, 7],  # Solo personas, bicis, coches, motos, bus, cami칩n\n",
    "    verbose=False  # Desactiva los prints de YOLO\n",
    ")\n",
    "\n",
    "total_detections = defaultdict(set)\n",
    "plate_tracker = {}\n",
    "frame_id = 0\n",
    "\n",
    "print(f\"\\n[INFO] Procesando {total_frames} frames...\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# LOOP PRINCIPAL\n",
    "# ============================================================\n",
    "for res in results_stream:\n",
    "    frame_id += 1\n",
    "    frame = res.orig_img.copy()\n",
    "    boxes = res.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        cls_id = int(box.cls)\n",
    "        if cls_id >= len(classNames):\n",
    "            continue\n",
    "        label = classNames[cls_id]\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "        conf = float(box.conf)\n",
    "        track_id = int(box.id) if box.id is not None else -1\n",
    "\n",
    "        # --- Conteo acumulado ---\n",
    "        if track_id != -1:\n",
    "            total_detections[label].add(track_id)\n",
    "\n",
    "        # ===== PERSONAS =====\n",
    "        if label == \"person\":\n",
    "            frame = blur_region(frame, x1, y1, x2, y2)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"Person {track_id}\", (x1, y1 - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "            continue\n",
    "\n",
    "        # ===== VEH칈CULOS =====\n",
    "        if label in VEHICLE_CLASSES:\n",
    "            mx1 = my1 = mx2 = my2 = -1\n",
    "            plate_conf = 0.0\n",
    "            plate_found = False\n",
    "            detection_method = \"none\"\n",
    "\n",
    "            crop = frame[y1:y2, x1:x2]\n",
    "            if crop.size > 0:\n",
    "                yolo_detection = None\n",
    "                ocr_detection = None\n",
    "                \n",
    "                # Detecci칩n con YOLO\n",
    "                lp_res = model_plate.predict(crop, conf=CONF_THRESHOLD, device=device, verbose=False)\n",
    "                if len(lp_res[0].boxes) > 0:\n",
    "                    best_box = max(lp_res[0].boxes, key=lambda b: b.conf)\n",
    "                    lx1, ly1, lx2, ly2 = map(int, best_box.xyxy[0].cpu().numpy())\n",
    "                    yolo_conf = float(best_box.conf)\n",
    "                    yolo_detection = (lx1, ly1, lx2, ly2, yolo_conf)\n",
    "                    detection_method = \"yolo\"\n",
    "                \n",
    "                # Detecci칩n con EasyOCR (solo cada N frames para no ralentizar)\n",
    "                if USE_EASYOCR and frame_id % 5 == 0:  # Solo cada 5 frames\n",
    "                    ocr_result = detect_plate_with_ocr(crop)\n",
    "                    if ocr_result:\n",
    "                        ocr_detection = ocr_result\n",
    "                        if yolo_detection is None:\n",
    "                            detection_method = \"ocr\"\n",
    "                        else:\n",
    "                            detection_method = \"yolo+ocr\"\n",
    "                \n",
    "                # Combinar detecciones\n",
    "                final_detection = merge_detections(yolo_detection, ocr_detection)\n",
    "                \n",
    "                if final_detection:\n",
    "                    lx1, ly1, lx2, ly2, plate_conf = final_detection\n",
    "                    mx1, my1, mx2, my2 = x1 + lx1, y1 + ly1, x1 + lx2, y1 + ly2\n",
    "                    plate_found = True\n",
    "\n",
    "            # --- Suavizado de coordenadas ---\n",
    "            if track_id != -1:\n",
    "                prev = plate_tracker.get(track_id, {}).get(\"pos\")\n",
    "                new_coords = (mx1, my1, mx2, my2) if plate_found else prev\n",
    "                smoothed = smooth_coords(prev, new_coords) if new_coords else None\n",
    "                if smoothed:\n",
    "                    mx1, my1, mx2, my2 = smoothed\n",
    "                    plate_tracker[track_id] = {\"pos\": smoothed, \"conf\": plate_conf}\n",
    "\n",
    "            # --- Blur de matr칤cula ---\n",
    "            if track_id in plate_tracker and plate_tracker[track_id].get(\"pos\"):\n",
    "                mx1, my1, mx2, my2 = plate_tracker[track_id][\"pos\"]\n",
    "                frame = blur_region(frame, mx1, my1, mx2, my2)\n",
    "                cv2.rectangle(frame, (mx1, my1), (mx2, my2), (0, 255, 0), 2)\n",
    "\n",
    "            # --- Caja del veh칤culo ---\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 128, 255), 2)\n",
    "            cv2.putText(frame, f\"{label} {track_id}\", (x1, y1 - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 128, 255), 2)\n",
    "\n",
    "            writer.writerow([frame_id, label, round(conf, 3), track_id,\n",
    "                             x1, y1, x2, y2, int(plate_found), round(plate_conf, 3),\n",
    "                             detection_method, mx1, my1, mx2, my2])\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    # Imprimir progreso cada 100 frames\n",
    "    if frame_id % 100 == 0:\n",
    "        print(f\"[INFO] Procesados {frame_id}/{total_frames} frames ({frame_id*100//total_frames}%)\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "csv_file.close()\n",
    "\n",
    "# ============================================================\n",
    "# RESULTADOS\n",
    "# ============================================================\n",
    "print(\"\\n========== RESULTADOS ==========\")\n",
    "for cls, ids in sorted(total_detections.items()):\n",
    "    print(f\"{cls}: {len(ids)} detectados en total\")\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intregraci칩n con seguimiento (tracking)\n",
    "!!!!!!!!!Nota: he tenido que bajar a la versi칩n de python 3.9.5 e instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "#model = YOLO('yolov11n-seg.pt') #M치scaras\n",
    "#model = YOLO('yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un v칤deo \n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "results = model.track(source=filename, show=True)  # BoT-SORT tracker (por defecto)\n",
    "#results = model.track(source=filename, show=True, tracker=\"bytetrack.yaml\")  # ByteTrack tracker\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
