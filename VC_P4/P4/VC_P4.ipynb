{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección de personas y vehículos con blur (sin OCR)\n",
    "Características:\n",
    "- YOLO11n para detección general + YOLO especializado para matrículas\n",
    "- Blur estable y centrado\n",
    "- IDs visibles en vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Dispositivo: CUDA\n",
      "[INFO] GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "[INFO] Procesando 2832 frames...\n",
      "\n",
      "[INFO] Procesados 100/2832 frames (3%)\n",
      "[INFO] Procesados 200/2832 frames (7%)\n",
      "[INFO] Procesados 300/2832 frames (10%)\n",
      "[INFO] Procesados 400/2832 frames (14%)\n",
      "[INFO] Procesados 500/2832 frames (17%)\n",
      "[INFO] Procesados 600/2832 frames (21%)\n",
      "[INFO] Procesados 700/2832 frames (24%)\n",
      "[INFO] Procesados 800/2832 frames (28%)\n",
      "[INFO] Procesados 900/2832 frames (31%)\n",
      "[INFO] Procesados 1000/2832 frames (35%)\n",
      "[INFO] Procesados 1100/2832 frames (38%)\n",
      "[INFO] Procesados 1200/2832 frames (42%)\n",
      "[INFO] Procesados 1300/2832 frames (45%)\n",
      "[INFO] Procesados 1400/2832 frames (49%)\n",
      "[INFO] Procesados 1500/2832 frames (52%)\n",
      "[INFO] Procesados 1600/2832 frames (56%)\n",
      "[INFO] Procesados 1700/2832 frames (60%)\n",
      "[INFO] Procesados 1800/2832 frames (63%)\n",
      "[INFO] Procesados 1900/2832 frames (67%)\n",
      "[INFO] Procesados 2000/2832 frames (70%)\n",
      "[INFO] Procesados 2100/2832 frames (74%)\n",
      "[INFO] Procesados 2200/2832 frames (77%)\n",
      "[INFO] Procesados 2300/2832 frames (81%)\n",
      "[INFO] Procesados 2400/2832 frames (84%)\n",
      "[INFO] Procesados 2500/2832 frames (88%)\n",
      "[INFO] Procesados 2600/2832 frames (91%)\n",
      "[INFO] Procesados 2700/2832 frames (95%)\n",
      "[INFO] Procesados 2800/2832 frames (98%)\n",
      "\n",
      "========== RESULTADOS ==========\n",
      "bicycle: 4 detectados en total\n",
      "car: 249 detectados en total\n",
      "motorbike: 9 detectados en total\n",
      "person: 49 detectados en total\n",
      "truck: 9 detectados en total\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================= CONFIG =========================\n",
    "VIDEO_IN_PATH = \"C0142.MP4\"\n",
    "VIDEO_OUT_PATH = \"outputs/salida_anonimizada.mp4\"\n",
    "CSV_OUT_PATH = \"outputs/detecciones.csv\"\n",
    "\n",
    "GENERAL_MODEL = \"yolo11n.pt\"\n",
    "PLATE_MODEL = \"best.pt\"\n",
    "\n",
    "CONF_THRESHOLD = 0.25\n",
    "BLUR_INTENSITY = 61\n",
    "MOVEMENT_THRESHOLD = 50\n",
    "# ============================================================\n",
    "\n",
    "import os, csv, cv2, torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "# GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"\\n[INFO] Dispositivo: {device.upper()}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"[INFO] GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# Modelos\n",
    "model_general = YOLO(GENERAL_MODEL).to(device)\n",
    "model_plate = YOLO(PLATE_MODEL).to(device)\n",
    "\n",
    "# Clases que nos interesan\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\"]\n",
    "VEHICLE_CLASSES = {\"car\", \"bus\", \"truck\", \"motorbike\", \"bicycle\"}\n",
    "\n",
    "# ====== FUNCIONES ======\n",
    "def blur_region(img, x1, y1, x2, y2, intensity=BLUR_INTENSITY):\n",
    "    \"\"\"Aplica blur controlando límites\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1, x2, y2 = map(int, [max(0, x1), max(0, y1), min(w, x2), min(h, y2)])\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return img\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    k = intensity if (x2 - x1) > 30 else 15\n",
    "    k = k if k % 2 == 1 else k + 1\n",
    "    blurred = cv2.GaussianBlur(roi, (k, k), 0)\n",
    "    img[y1:y2, x1:x2] = blurred\n",
    "    return img\n",
    "\n",
    "def smooth_coords(prev, new, alpha=0.5):\n",
    "    \"\"\"Suavizado exponencial de coordenadas\"\"\"\n",
    "    if prev is None:\n",
    "        return new\n",
    "    return tuple(int(p * (1 - alpha) + n * alpha) for p, n in zip(prev, new))\n",
    "\n",
    "# ====== VIDEO ======\n",
    "cap = cv2.VideoCapture(VIDEO_IN_PATH)\n",
    "width, height = int(cap.get(3)), int(cap.get(4))\n",
    "fps = cap.get(5) or 25\n",
    "total_frames = int(cap.get(7))\n",
    "\n",
    "out = cv2.VideoWriter(VIDEO_OUT_PATH, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
    "\n",
    "# ====== CSV ======\n",
    "csv_file = open(CSV_OUT_PATH, \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "writer = csv.writer(csv_file)\n",
    "writer.writerow([\"frame\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "                 \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "                 \"matricula_detectada\", \"conf_matricula\",\n",
    "                 \"mx1\", \"my1\", \"mx2\", \"my2\"])\n",
    "\n",
    "# ====== TRACKING ======\n",
    "results_stream = model_general.track(\n",
    "    source=VIDEO_IN_PATH,\n",
    "    tracker=\"botsort.yaml\",\n",
    "    stream=True,\n",
    "    device=device,\n",
    "    classes=[0, 1, 2, 3, 5, 7],  # Solo personas, bicis, coches, motos, bus, camión\n",
    "    verbose=False  # Desactiva los prints de YOLO\n",
    ")\n",
    "\n",
    "total_detections = defaultdict(set)\n",
    "plate_tracker = {}\n",
    "frame_id = 0\n",
    "\n",
    "print(f\"\\n[INFO] Procesando {total_frames} frames...\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# LOOP PRINCIPAL\n",
    "# ============================================================\n",
    "for res in results_stream:\n",
    "    frame_id += 1\n",
    "    frame = res.orig_img.copy()\n",
    "    boxes = res.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        cls_id = int(box.cls)\n",
    "        if cls_id >= len(classNames):\n",
    "            continue\n",
    "        label = classNames[cls_id]\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "        conf = float(box.conf)\n",
    "        track_id = int(box.id) if box.id is not None else -1\n",
    "\n",
    "        # --- Conteo acumulado ---\n",
    "        if track_id != -1:\n",
    "            total_detections[label].add(track_id)\n",
    "\n",
    "        # ===== PERSONAS =====\n",
    "        if label == \"person\":\n",
    "            frame = blur_region(frame, x1, y1, x2, y2)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"Person {track_id}\", (x1, y1 - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "            continue\n",
    "\n",
    "        # ===== VEHÍCULOS =====\n",
    "        if label in VEHICLE_CLASSES:\n",
    "            mx1 = my1 = mx2 = my2 = -1\n",
    "            plate_conf = 0.0\n",
    "            plate_found = False\n",
    "\n",
    "            crop = frame[y1:y2, x1:x2]\n",
    "            if crop.size > 0:\n",
    "                lp_res = model_plate.predict(crop, conf=CONF_THRESHOLD, device=device, verbose=False)\n",
    "                if len(lp_res[0].boxes) > 0:\n",
    "                    # --- Usa la de mayor confianza ---\n",
    "                    best_box = max(lp_res[0].boxes, key=lambda b: b.conf)\n",
    "                    lx1, ly1, lx2, ly2 = map(int, best_box.xyxy[0].cpu().numpy())\n",
    "                    mx1, my1, mx2, my2 = x1 + lx1, y1 + ly1, x1 + lx2, y1 + ly2\n",
    "                    plate_conf = float(best_box.conf)\n",
    "                    plate_found = True\n",
    "\n",
    "            # --- Suavizado de coordenadas ---\n",
    "            if track_id != -1:\n",
    "                prev = plate_tracker.get(track_id, {}).get(\"pos\")\n",
    "                new_coords = (mx1, my1, mx2, my2) if plate_found else prev\n",
    "                smoothed = smooth_coords(prev, new_coords) if new_coords else None\n",
    "                if smoothed:\n",
    "                    mx1, my1, mx2, my2 = smoothed\n",
    "                    plate_tracker[track_id] = {\"pos\": smoothed, \"conf\": plate_conf}\n",
    "\n",
    "            # --- Blur de matrícula ---\n",
    "            if track_id in plate_tracker and plate_tracker[track_id].get(\"pos\"):\n",
    "                mx1, my1, mx2, my2 = plate_tracker[track_id][\"pos\"]\n",
    "                frame = blur_region(frame, mx1, my1, mx2, my2)\n",
    "                cv2.rectangle(frame, (mx1, my1), (mx2, my2), (0, 255, 0), 2)\n",
    "\n",
    "            # --- Caja del vehículo ---\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 128, 255), 2)\n",
    "            cv2.putText(frame, f\"{label} {track_id}\", (x1, y1 - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 128, 255), 2)\n",
    "\n",
    "            writer.writerow([frame_id, label, round(conf, 3), track_id,\n",
    "                             x1, y1, x2, y2, int(plate_found), round(plate_conf, 3),\n",
    "                             mx1, my1, mx2, my2])\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    # Imprimir progreso cada 100 frames\n",
    "    if frame_id % 100 == 0:\n",
    "        print(f\"[INFO] Procesados {frame_id}/{total_frames} frames ({frame_id*100//total_frames}%)\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "csv_file.close()\n",
    "\n",
    "# ============================================================\n",
    "# RESULTADOS\n",
    "# ============================================================\n",
    "print(\"\\n========== RESULTADOS ==========\")\n",
    "for cls, ids in sorted(total_detections.items()):\n",
    "    print(f\"{cls}: {len(ids)} detectados en total\")\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección de personas y vehículos con blur (con OCR)\n",
    "Características:\n",
    "- YOLO11n para detección general + YOLO especializado para matrículas\n",
    "- Blur estable y centrado\n",
    "- IDs visibles en vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Dispositivo: CUDA\n",
      "[INFO] GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "[INFO] Inicializando EasyOCR...\n",
      "[INFO] EasyOCR listo\n",
      "\n",
      "[INFO] Procesando 2832 frames...\n",
      "\n",
      "[INFO] Procesados 100/2832 frames (3%)\n",
      "[INFO] Procesados 200/2832 frames (7%)\n",
      "[INFO] Procesados 300/2832 frames (10%)\n",
      "[INFO] Procesados 400/2832 frames (14%)\n",
      "[INFO] Procesados 500/2832 frames (17%)\n",
      "[INFO] Procesados 600/2832 frames (21%)\n",
      "[INFO] Procesados 700/2832 frames (24%)\n",
      "[INFO] Procesados 800/2832 frames (28%)\n",
      "[INFO] Procesados 900/2832 frames (31%)\n",
      "[INFO] Procesados 1000/2832 frames (35%)\n",
      "[INFO] Procesados 1100/2832 frames (38%)\n",
      "[INFO] Procesados 1200/2832 frames (42%)\n",
      "[INFO] Procesados 1300/2832 frames (45%)\n",
      "[INFO] Procesados 1400/2832 frames (49%)\n",
      "[INFO] Procesados 1500/2832 frames (52%)\n",
      "[INFO] Procesados 1600/2832 frames (56%)\n",
      "[INFO] Procesados 1700/2832 frames (60%)\n",
      "[INFO] Procesados 1800/2832 frames (63%)\n",
      "[INFO] Procesados 1900/2832 frames (67%)\n",
      "[INFO] Procesados 2000/2832 frames (70%)\n",
      "[INFO] Procesados 2100/2832 frames (74%)\n",
      "[INFO] Procesados 2200/2832 frames (77%)\n",
      "[INFO] Procesados 2300/2832 frames (81%)\n",
      "[INFO] Procesados 2400/2832 frames (84%)\n",
      "[INFO] Procesados 2500/2832 frames (88%)\n",
      "[INFO] Procesados 2600/2832 frames (91%)\n",
      "[INFO] Procesados 2700/2832 frames (95%)\n",
      "[INFO] Procesados 2800/2832 frames (98%)\n",
      "\n",
      "========== RESULTADOS ==========\n",
      "bicycle: 4 detectados en total\n",
      "car: 249 detectados en total\n",
      "motorbike: 9 detectados en total\n",
      "person: 49 detectados en total\n",
      "truck: 9 detectados en total\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "# ========================= CONFIG =========================\n",
    "VIDEO_IN_PATH = \"C0142.MP4\"\n",
    "VIDEO_OUT_PATH = \"outputs/salida_anonimizada.mp4\"\n",
    "CSV_OUT_PATH = \"outputs/detecciones.csv\"\n",
    "\n",
    "GENERAL_MODEL = \"yolo11n.pt\"\n",
    "PLATE_MODEL = \"best.pt\"\n",
    "\n",
    "CONF_THRESHOLD = 0.25\n",
    "BLUR_INTENSITY = 61\n",
    "USE_EASYOCR = True\n",
    "# ============================================================\n",
    "\n",
    "import os, csv, cv2, torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import easyocr\n",
    "\n",
    "# GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"\\n[INFO] Dispositivo: {device.upper()}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"[INFO] GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# Modelos\n",
    "model_general = YOLO(GENERAL_MODEL).to(device)\n",
    "model_plate = YOLO(PLATE_MODEL).to(device)\n",
    "\n",
    "# EasyOCR (solo para detectar región, no leer)\n",
    "if USE_EASYOCR:\n",
    "    print(\"[INFO] Inicializando EasyOCR...\")\n",
    "    reader = easyocr.Reader(['en'], gpu=(device == 'cuda'), verbose=False)\n",
    "    print(\"[INFO] EasyOCR listo\")\n",
    "\n",
    "# Clases que nos interesan\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\"]\n",
    "VEHICLE_CLASSES = {\"car\", \"bus\", \"truck\", \"motorbike\", \"bicycle\"}\n",
    "\n",
    "# ====== FUNCIONES ======\n",
    "def blur_region(img, x1, y1, x2, y2, intensity=BLUR_INTENSITY):\n",
    "    \"\"\"Aplica blur controlando límites\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1, x2, y2 = map(int, [max(0, x1), max(0, y1), min(w, x2), min(h, y2)])\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return img\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    k = intensity if (x2 - x1) > 30 else 15\n",
    "    k = k if k % 2 == 1 else k + 1\n",
    "    blurred = cv2.GaussianBlur(roi, (k, k), 0)\n",
    "    img[y1:y2, x1:x2] = blurred\n",
    "    return img\n",
    "\n",
    "def smooth_coords(prev, new, alpha=0.5):\n",
    "    \"\"\"Suavizado exponencial de coordenadas\"\"\"\n",
    "    if prev is None:\n",
    "        return new\n",
    "    return tuple(int(p * (1 - alpha) + n * alpha) for p, n in zip(prev, new))\n",
    "\n",
    "def detect_plate_with_ocr(crop):\n",
    "    \"\"\"Detecta región de matrícula usando EasyOCR (sin leer)\"\"\"\n",
    "    try:\n",
    "        results = reader.readtext(crop, paragraph=False)\n",
    "        if results:\n",
    "            # Buscar el texto más parecido a una matrícula (alfanumérico)\n",
    "            for (bbox, text, conf) in results:\n",
    "                # Solo nos interesan detecciones con confianza razonable\n",
    "                if conf > 0.3 and any(c.isalnum() for c in text):\n",
    "                    # bbox es [[x1,y1], [x2,y1], [x2,y2], [x1,y2]]\n",
    "                    pts = np.array(bbox, dtype=np.int32)\n",
    "                    x1 = int(pts[:, 0].min())\n",
    "                    y1 = int(pts[:, 1].min())\n",
    "                    x2 = int(pts[:, 0].max())\n",
    "                    y2 = int(pts[:, 1].max())\n",
    "                    return (x1, y1, x2, y2, conf)\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def merge_detections(yolo_box, ocr_box):\n",
    "    \"\"\"Combina detecciones de YOLO y OCR para obtener mejor región\"\"\"\n",
    "    if yolo_box is None and ocr_box is None:\n",
    "        return None\n",
    "    if yolo_box is None:\n",
    "        return ocr_box\n",
    "    if ocr_box is None:\n",
    "        return yolo_box\n",
    "    \n",
    "    # Usar la detección con mayor confianza o fusionar\n",
    "    yx1, yy1, yx2, yy2, yconf = yolo_box\n",
    "    ox1, oy1, ox2, oy2, oconf = ocr_box\n",
    "    \n",
    "    # Si las cajas se solapan, usar la de mayor confianza\n",
    "    if yconf > oconf:\n",
    "        return yolo_box\n",
    "    else:\n",
    "        return ocr_box\n",
    "\n",
    "# ====== VIDEO ======\n",
    "cap = cv2.VideoCapture(VIDEO_IN_PATH)\n",
    "width, height = int(cap.get(3)), int(cap.get(4))\n",
    "fps = cap.get(5) or 25\n",
    "total_frames = int(cap.get(7))\n",
    "\n",
    "out = cv2.VideoWriter(VIDEO_OUT_PATH, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
    "\n",
    "# ====== CSV ======\n",
    "csv_file = open(CSV_OUT_PATH, \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "writer = csv.writer(csv_file)\n",
    "writer.writerow([\"frame\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "                 \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "                 \"matricula_detectada\", \"conf_matricula\", \"metodo_deteccion\",\n",
    "                 \"mx1\", \"my1\", \"mx2\", \"my2\"])\n",
    "\n",
    "# ====== TRACKING ======\n",
    "results_stream = model_general.track(\n",
    "    source=VIDEO_IN_PATH,\n",
    "    tracker=\"botsort.yaml\",\n",
    "    stream=True,\n",
    "    device=device,\n",
    "    classes=[0, 1, 2, 3, 5, 7],  # Solo personas, bicis, coches, motos, bus, camión\n",
    "    verbose=False  # Desactiva los prints de YOLO\n",
    ")\n",
    "\n",
    "total_detections = defaultdict(set)\n",
    "plate_tracker = {}\n",
    "frame_id = 0\n",
    "\n",
    "print(f\"\\n[INFO] Procesando {total_frames} frames...\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# LOOP PRINCIPAL\n",
    "# ============================================================\n",
    "for res in results_stream:\n",
    "    frame_id += 1\n",
    "    frame = res.orig_img.copy()\n",
    "    boxes = res.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        cls_id = int(box.cls)\n",
    "        if cls_id >= len(classNames):\n",
    "            continue\n",
    "        label = classNames[cls_id]\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "        conf = float(box.conf)\n",
    "        track_id = int(box.id) if box.id is not None else -1\n",
    "\n",
    "        # --- Conteo acumulado ---\n",
    "        if track_id != -1:\n",
    "            total_detections[label].add(track_id)\n",
    "\n",
    "        # ===== PERSONAS =====\n",
    "        if label == \"person\":\n",
    "            frame = blur_region(frame, x1, y1, x2, y2)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"Person {track_id}\", (x1, y1 - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "            continue\n",
    "\n",
    "        # ===== VEHÍCULOS =====\n",
    "        if label in VEHICLE_CLASSES:\n",
    "            mx1 = my1 = mx2 = my2 = -1\n",
    "            plate_conf = 0.0\n",
    "            plate_found = False\n",
    "            detection_method = \"none\"\n",
    "\n",
    "            crop = frame[y1:y2, x1:x2]\n",
    "            if crop.size > 0:\n",
    "                yolo_detection = None\n",
    "                ocr_detection = None\n",
    "                \n",
    "                # Detección con YOLO\n",
    "                lp_res = model_plate.predict(crop, conf=CONF_THRESHOLD, device=device, verbose=False)\n",
    "                if len(lp_res[0].boxes) > 0:\n",
    "                    best_box = max(lp_res[0].boxes, key=lambda b: b.conf)\n",
    "                    lx1, ly1, lx2, ly2 = map(int, best_box.xyxy[0].cpu().numpy())\n",
    "                    yolo_conf = float(best_box.conf)\n",
    "                    yolo_detection = (lx1, ly1, lx2, ly2, yolo_conf)\n",
    "                    detection_method = \"yolo\"\n",
    "                \n",
    "                # Detección con EasyOCR (solo cada N frames para no ralentizar)\n",
    "                if USE_EASYOCR and frame_id % 5 == 0:  # Solo cada 5 frames\n",
    "                    ocr_result = detect_plate_with_ocr(crop)\n",
    "                    if ocr_result:\n",
    "                        ocr_detection = ocr_result\n",
    "                        if yolo_detection is None:\n",
    "                            detection_method = \"ocr\"\n",
    "                        else:\n",
    "                            detection_method = \"yolo+ocr\"\n",
    "                \n",
    "                # Combinar detecciones\n",
    "                final_detection = merge_detections(yolo_detection, ocr_detection)\n",
    "                \n",
    "                if final_detection:\n",
    "                    lx1, ly1, lx2, ly2, plate_conf = final_detection\n",
    "                    mx1, my1, mx2, my2 = x1 + lx1, y1 + ly1, x1 + lx2, y1 + ly2\n",
    "                    plate_found = True\n",
    "\n",
    "            # --- Suavizado de coordenadas ---\n",
    "            if track_id != -1:\n",
    "                prev = plate_tracker.get(track_id, {}).get(\"pos\")\n",
    "                new_coords = (mx1, my1, mx2, my2) if plate_found else prev\n",
    "                smoothed = smooth_coords(prev, new_coords) if new_coords else None\n",
    "                if smoothed:\n",
    "                    mx1, my1, mx2, my2 = smoothed\n",
    "                    plate_tracker[track_id] = {\"pos\": smoothed, \"conf\": plate_conf}\n",
    "\n",
    "            # --- Blur de matrícula ---\n",
    "            if track_id in plate_tracker and plate_tracker[track_id].get(\"pos\"):\n",
    "                mx1, my1, mx2, my2 = plate_tracker[track_id][\"pos\"]\n",
    "                frame = blur_region(frame, mx1, my1, mx2, my2)\n",
    "                cv2.rectangle(frame, (mx1, my1), (mx2, my2), (0, 255, 0), 2)\n",
    "\n",
    "            # --- Caja del vehículo ---\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 128, 255), 2)\n",
    "            cv2.putText(frame, f\"{label} {track_id}\", (x1, y1 - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 128, 255), 2)\n",
    "\n",
    "            writer.writerow([frame_id, label, round(conf, 3), track_id,\n",
    "                             x1, y1, x2, y2, int(plate_found), round(plate_conf, 3),\n",
    "                             detection_method, mx1, my1, mx2, my2])\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    # Imprimir progreso cada 100 frames\n",
    "    if frame_id % 100 == 0:\n",
    "        print(f\"[INFO] Procesados {frame_id}/{total_frames} frames ({frame_id*100//total_frames}%)\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "csv_file.close()\n",
    "\n",
    "# ============================================================\n",
    "# RESULTADOS\n",
    "# ============================================================\n",
    "print(\"\\n========== RESULTADOS ==========\")\n",
    "for cls, ids in sorted(total_detections.items()):\n",
    "    print(f\"{cls}: {len(ids)} detectados en total\")\n",
    "print(\"================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
