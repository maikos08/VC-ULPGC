# üöó Pr√°ctica 4 ‚Äî Detecci√≥n de Veh√≠culos y Matr√≠culas

## üë• Autores
- Alberto Jos√© Rodr√≠guez Ruano  
- Miguel √Ångel Rodr√≠guez Ruano  

---

## üß† Descripci√≥n general
Este proyecto implementa un prototipo basado en visi√≥n por computador para la detecci√≥n, seguimiento y anonimizaci√≥n (blur) de personas y veh√≠culos en v√≠deo, incluyendo la localizaci√≥n de matr√≠culas mediante modelos YOLO11 .  
El notebook principal es `VC_P4.ipynb`.

---

## üìö Contenidos
- Objetivo  
- Estructura del notebook  
- Requisitos e instalaci√≥n  
- Par√°metros principales  
- C√≥mo ejecutar  
- Formato del CSV  
- Ejemplo r√°pido  
- Limitaciones y notas  
- Referencias  
- Fragmentos √∫tiles  

---

## üéØ Objetivo
Procesar un v√≠deo y realizar:
- Detecci√≥n y seguimiento de personas y veh√≠culos (YOLO11).
- Localizaci√≥n de matr√≠culas dentro de veh√≠culos (YOLO + EasyOCR opcional).
- Aplicar desenfoque selectivo sobre regiones sensibles.
- Exportar un v√≠deo anonimizado y un CSV con metadatos.

### Variantes
1. Sin OCR: detecci√≥n + blur con YOLO.  
2. Con OCR: detecci√≥n combinada YOLO + EasyOCR.

---

## üß© Estructura del notebook
- Configuraci√≥n: rutas, modelos y umbrales.  
- Modelos:  
  - model_general (YOLO11n) para detecci√≥n general.  
  - model_plate (best.pt) para matr√≠culas.  
  - easyocr.Reader opcional.  
- Funciones utilitarias:  
  - blur_region()  
  - smooth_coords()  
  - detect_plate_with_ocr()  
  - merge_detections()  
- Loop principal: procesamiento de v√≠deo frame a frame con tracking BoT-SORT.

---

## ‚öôÔ∏è Requisitos e instalaci√≥n
Crear entorno con Python 3.9:

```bash
conda create -n VC_P4 python=3.9 -y
conda activate VC_P4
pip install ultralytics opencv-python-headless numpy pandas easyocr torch torchvision
```


Notas:
- Si se desea usar GPU, instalar torch con CUDA desde pytorch.org.
- Si opencv-python-headless causa problemas, usar opencv-python.
- Si no se usa OCR, dejar USE_EASYOCR=False.

### Modelos requeridos
Colocar los pesos en la carpeta del notebook:
- yolo11n.pt ‚Üí modelo general.
- best.pt ‚Üí detector de matr√≠culas.
- botsort.yaml ‚Üí configuraci√≥n del tracker.

---

## üß∞ Par√°metros principales
Par√°metro | Descripci√≥n | Valor por defecto
-----------|--------------|------------------
VIDEO_IN_PATH | Ruta del v√≠deo de entrada | C0142.MP4
VIDEO_OUT_PATH | V√≠deo anonimizado | outputs/salida_anonimizada.mp4
CSV_OUT_PATH | CSV de detecciones | outputs/detecciones.csv
GENERAL_MODEL | Modelo YOLO general | yolo11n.pt
PLATE_MODEL | Modelo de matr√≠culas | best.pt
CONF_THRESHOLD | Umbral de confianza | 0.25
BLUR_INTENSITY | Nivel de desenfoque | 61
USE_EASYOCR | Activar OCR auxiliar | False

Editar estos valores en las primeras celdas del notebook.

---

## ‚ñ∂Ô∏è C√≥mo ejecutar
1. Abrir VC_P4.ipynb en Jupyter o VSCode.  
2. Asegurarse de que los pesos est√©n disponibles.  
3. Ejecutar las celdas en orden: configuraci√≥n ‚Üí carga de modelos ‚Üí loop principal.  
4. Se generar√°n:
   - outputs/salida_anonimizada.mp4  
   - outputs/detecciones.csv  

Si USE_EASYOCR=True, EasyOCR refinar√° la detecci√≥n de matr√≠culas cada N frames.

---

## üìä Formato del CSV generado
Cada fila representa una detecci√≥n por frame:

Columna | Descripci√≥n
--------|-------------
frame | N√∫mero de frame
tipo_objeto | Clase detectada (person, car‚Ä¶)
confianza | Confianza de la detecci√≥n
id_tracking | ID de seguimiento (BoT-SORT)
x1,y1,x2,y2 | Coordenadas de la caja
matricula_detectada | 1 si hay placa, 0 si no
conf_matricula | Confianza de la placa
metodo_deteccion | yolo, ocr o yolo+ocr
mx1,my1,mx2,my2 | Coordenadas de la caja de la placa

---

## ‚ö° Ejemplo r√°pido
üë§ Personas ‚Üí se desenfocan completamente con blur_region.  
üöó Veh√≠culos ‚Üí se detecta placa con model_plate.  
üî† OCR ‚Üí si est√° activo, EasyOCR refina detecciones y se fusiona con YOLO.  
üìâ Suavizado ‚Üí smooth_coords evita parpadeos entre frames.

---

## ‚ö†Ô∏è Limitaciones
- La calidad depende de la resoluci√≥n y del modelo best.pt.
- EasyOCR a√±ade carga computacional; se ejecuta cada N frames.
- Para CPU o v√≠deos largos, reducir FPS o subir CONF_THRESHOLD.
- Para lectura OCR avanzada, ver VC_P4b.ipynb.

---

## üìö Referencias
- Ultralytics YOLO: https://github.com/ultralytics/ultralytics  
- EasyOCR: https://github.com/JaidedAI/EasyOCR  
- PyTorch: https://pytorch.org  
- ChatGPT: https://chat.openai.com  

---

## üíª Fragmentos de c√≥digo √∫tiles

1Ô∏è‚É£ Configuraci√≥n m√≠nima:
```python
VIDEO_IN_PATH = "C0142.MP4"
VIDEO_OUT_PATH = "outputs/salida_anonimizada.mp4"
CSV_OUT_PATH = "outputs/detecciones.csv"
GENERAL_MODEL = "yolo11n.pt"
PLATE_MODEL = "best.pt"
CONF_THRESHOLD = 0.25
BLUR_INTENSITY = 61
USE_EASYOCR = True
```

2Ô∏è‚É£ Funci√≥n de blur:
```python
def blur_region(img, x1, y1, x2, y2, intensity=BLUR_INTENSITY):
    h, w = img.shape[:2]
    x1, y1, x2, y2 = map(int, [max(0, x1), max(0, y1), min(w, x2), min(h, y2)])
    if x2 <= x1 or y2 <= y1:
        return img
    roi = img[y1:y2, x1:x2]
    k = intensity if (x2 - x1) > 30 else 15
    k = k if k % 2 == 1 else k + 1
    blurred = cv2.GaussianBlur(roi, (k, k), 0)
    img[y1:y2, x1:x2] = blurred
    return img
```

3Ô∏è‚É£ Combinar YOLO + OCR:
```python
def merge_detections(yolo_box, ocr_box):
    if yolo_box is None and ocr_box is None:
        return None
    if yolo_box is None:
        return ocr_box
    if ocr_box is None:
        return yolo_box
    yx1, yy1, yx2, yy2, yconf = yolo_box
    ox1, oy1, ox2, oy2, oconf = ocr_box
    return yolo_box if yconf > oconf else ocr_box
```

---

## üñºÔ∏è Ejemplos visuales
![Ejemplo 1](./Captura-readme1.png)
![Ejemplo 2](./Captura-readme2.png)

---

## üßæ Notas finales
Este notebook constituye la parte principal del pipeline de visi√≥n de la pr√°ctica, y puede combinarse con el m√≥dulo VC_P4b para tareas de OCR avanzado y m√©tricas.  
Ambos m√≥dulos conforman el flujo completo de detecci√≥n, anonimizaci√≥n y an√°lisis de matr√≠culas.
