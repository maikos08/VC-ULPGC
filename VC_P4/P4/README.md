# ğŸš— PrÃ¡ctica 4 â€” DetecciÃ³n de VehÃ­culos y MatrÃ­culas

## ğŸ‘¥ Autores
- Alberto JosÃ© RodrÃ­guez Ruano  
- Miguel Ãngel RodrÃ­guez Ruano  

---

## ğŸ§  DescripciÃ³n general
Este proyecto implementa un prototipo basado en visiÃ³n por computador para la detecciÃ³n, seguimiento y anonimizaciÃ³n (blur) de personas y vehÃ­culos en vÃ­deo, incluyendo la localizaciÃ³n de matrÃ­culas mediante modelos YOLO11 .  
El notebook principal es `VC_P4.ipynb`.

---

## ğŸ“š Contenidos
- Objetivo  
- Estructura del notebook  
- Requisitos e instalaciÃ³n  
- ParÃ¡metros principales  
- CÃ³mo ejecutar  
- Formato del CSV  
- Ejemplo rÃ¡pido  
- Limitaciones y notas  
- Referencias  
- Fragmentos Ãºtiles  

---

## ğŸ¯ Objetivo
Procesar un vÃ­deo y realizar:
- DetecciÃ³n y seguimiento de personas y vehÃ­culos (YOLO11).
- LocalizaciÃ³n de matrÃ­culas dentro de vehÃ­culos (YOLO + EasyOCR opcional).
- Aplicar desenfoque selectivo sobre regiones sensibles.
- Exportar un vÃ­deo anonimizado y un CSV con metadatos.

### Variantes
1. Sin OCR: detecciÃ³n + blur con YOLO.  
2. Con OCR: detecciÃ³n combinada YOLO + EasyOCR.

---

## ğŸ§© Estructura del notebook
- ConfiguraciÃ³n: rutas, modelos y umbrales.  
- Modelos:  
  - model_general (YOLO11n) para detecciÃ³n general.  
  - model_plate (best.pt) para matrÃ­culas.  
  - easyocr.Reader opcional.  
- Funciones utilitarias:  
  - blur_region()  
  - smooth_coords()  
  - detect_plate_with_ocr()  
  - merge_detections()  
- Loop principal: procesamiento de vÃ­deo frame a frame con tracking BoT-SORT.

---

## ğŸ“‚ Dataset utilizado

El conjunto de datos empleado para el entrenamiento del modelo YOLO destinado a la detecciÃ³n de matrÃ­culas estÃ¡ disponible en el siguiente enlace:

### ğŸ”— Descargar dataset:
https://drive.google.com/file/d/1MHEGWN_suCMlTrA9IHJFPZ2wKu8hqrGo/view?usp=sharing


---

## âš™ï¸ Resultados del entrenamiento

![Ejemplo 3](../resultados-del-entrenamiento/results.png)


### ğŸ“‰ PÃ©rdidas (Losses)

| MÃ©trica | DescripciÃ³n | Tendencia |
|----------|--------------|-----------|
| **train/box_loss** | Error en la predicciÃ³n de las cajas delimitadoras. | ğŸ”» Disminuye progresivamente. |
| **train/cls_loss** | Error al clasificar los objetos detectados. | ğŸ”» Disminuye rÃ¡pidamente. |
| **train/dfl_loss** | Distribution Focal Loss (mejora precisiÃ³n de cajas). | ğŸ”» Disminuye constante. |
| **val/box_loss** | PÃ©rdida de cajas en validaciÃ³n. | ğŸ”» Disminuye, algo irregular. |
| **val/cls_loss** | PÃ©rdida de clasificaciÃ³n en validaciÃ³n. | ğŸ”» Disminuye bien. |
| **val/dfl_loss** | PÃ©rdida DFL en validaciÃ³n. | ğŸ”» Disminuye correctamente. |


### ğŸ“ˆ MÃ©tricas de Rendimiento

| MÃ©trica | DescripciÃ³n | Tendencia |
|----------|--------------|-----------|
| **metrics/precision(B)** | ProporciÃ³n de detecciones correctas (evita falsos positivos). | ğŸ”¼ Sube hasta ~0.9 |
| **metrics/recall(B)** | ProporciÃ³n de objetos detectados (evita falsos negativos). | ğŸ”¼ Sube hasta ~0.85 |
| **metrics/mAP50(B)** | PrecisiÃ³n promedio a IoU=0.5. | ğŸ”¼ Sube hasta ~0.9 |
| **metrics/mAP50-95(B)** | PrecisiÃ³n promedio a IoU entre 0.5 y 0.95 (mÃ¡s estricta). | ğŸ”¼ Sube hasta ~0.5 |

###  Conclusiones

- El modelo muestra **una clara convergencia**: las pÃ©rdidas bajan y las mÃ©tricas suben.
- **No hay signos de sobreajuste**, ya que las curvas de validaciÃ³n siguen el mismo patrÃ³n que las de entrenamiento.
- Los valores finales de **mAP50 (~0.9)** y **mAP50-95 (~0.5)** indican **buen rendimiento en detecciÃ³n**.


---

## âš™ï¸ Requisitos e instalaciÃ³n
Crear entorno con Python 3.9:

```bash
conda create -n VC_P4 python=3.9 -y
conda activate VC_P4
pip install ultralytics opencv-python-headless numpy pandas easyocr torch torchvision
```


Notas:
- Si se desea usar GPU, instalar torch con CUDA desde pytorch.org.
- Si opencv-python-headless causa problemas, usar opencv-python.
- Si no se usa OCR, dejar USE_EASYOCR=False.

### Modelos requeridos
Colocar los pesos en la carpeta del notebook:
- yolo11n.pt â†’ modelo general.
- best.pt â†’ detector de matrÃ­culas.
- botsort.yaml â†’ configuraciÃ³n del tracker.

---

## ğŸ§° ParÃ¡metros principales
ParÃ¡metro | DescripciÃ³n | Valor por defecto
-----------|--------------|------------------
VIDEO_IN_PATH | Ruta del vÃ­deo de entrada | C0142.MP4
VIDEO_OUT_PATH | VÃ­deo anonimizado | outputs/salida_anonimizada.mp4
CSV_OUT_PATH | CSV de detecciones | outputs/detecciones.csv
GENERAL_MODEL | Modelo YOLO general | yolo11n.pt
PLATE_MODEL | Modelo de matrÃ­culas | best.pt
CONF_THRESHOLD | Umbral de confianza | 0.25
BLUR_INTENSITY | Nivel de desenfoque | 61
USE_EASYOCR | Activar OCR auxiliar | False

Editar estos valores en las primeras celdas del notebook.

---

## â–¶ï¸ CÃ³mo ejecutar
1. Abrir VC_P4.ipynb en Jupyter o VSCode.  
2. Asegurarse de que los pesos estÃ©n disponibles.  
3. Ejecutar las celdas en orden: configuraciÃ³n â†’ carga de modelos â†’ loop principal.  
4. Se generarÃ¡n:
   - outputs/salida_anonimizada.mp4  
   - outputs/detecciones.csv  

Si USE_EASYOCR=True, EasyOCR refinarÃ¡ la detecciÃ³n de matrÃ­culas cada N frames.

---

## ğŸ“Š Formato del CSV generado
Cada fila representa una detecciÃ³n por frame:

Columna | DescripciÃ³n
--------|-------------
frame | NÃºmero de frame
tipo_objeto | Clase detectada (person, carâ€¦)
confianza | Confianza de la detecciÃ³n
id_tracking | ID de seguimiento (BoT-SORT)
x1,y1,x2,y2 | Coordenadas de la caja
matricula_detectada | 1 si hay placa, 0 si no
conf_matricula | Confianza de la placa
metodo_deteccion | yolo, ocr o yolo+ocr
mx1,my1,mx2,my2 | Coordenadas de la caja de la placa

---

## âš¡ Ejemplo rÃ¡pido
ğŸ‘¤ Personas â†’ se desenfocan completamente con blur_region.  
ğŸš— VehÃ­culos â†’ se detecta placa con model_plate.  
ğŸ”  OCR â†’ si estÃ¡ activo, EasyOCR refina detecciones y se fusiona con YOLO.  
ğŸ“‰ Suavizado â†’ smooth_coords evita parpadeos entre frames.

---

## âš ï¸ Limitaciones
- La calidad depende de la resoluciÃ³n y del modelo best.pt.
- EasyOCR aÃ±ade carga computacional; se ejecuta cada N frames.
- Para CPU o vÃ­deos largos, reducir FPS o subir CONF_THRESHOLD.
- Para lectura OCR avanzada, ver VC_P4b.ipynb.

---

## ğŸ“š Referencias
- Ultralytics YOLO: https://github.com/ultralytics/ultralytics  
- EasyOCR: https://github.com/JaidedAI/EasyOCR  
- PyTorch: https://pytorch.org  
- ChatGPT: https://chat.openai.com  

---

## ğŸ’» Fragmentos de cÃ³digo Ãºtiles

1ï¸âƒ£ ConfiguraciÃ³n mÃ­nima:
```python
VIDEO_IN_PATH = "C0142.MP4"
VIDEO_OUT_PATH = "outputs/salida_anonimizada.mp4"
CSV_OUT_PATH = "outputs/detecciones.csv"
GENERAL_MODEL = "yolo11n.pt"
PLATE_MODEL = "best.pt"
CONF_THRESHOLD = 0.25
BLUR_INTENSITY = 61
USE_EASYOCR = True
```

2ï¸âƒ£ FunciÃ³n de blur:
```python
def blur_region(img, x1, y1, x2, y2, intensity=BLUR_INTENSITY):
    h, w = img.shape[:2]
    x1, y1, x2, y2 = map(int, [max(0, x1), max(0, y1), min(w, x2), min(h, y2)])
    if x2 <= x1 or y2 <= y1:
        return img
    roi = img[y1:y2, x1:x2]
    k = intensity if (x2 - x1) > 30 else 15
    k = k if k % 2 == 1 else k + 1
    blurred = cv2.GaussianBlur(roi, (k, k), 0)
    img[y1:y2, x1:x2] = blurred
    return img
```

3ï¸âƒ£ Combinar YOLO + OCR:
```python
def merge_detections(yolo_box, ocr_box):
    if yolo_box is None and ocr_box is None:
        return None
    if yolo_box is None:
        return ocr_box
    if ocr_box is None:
        return yolo_box
    yx1, yy1, yx2, yy2, yconf = yolo_box
    ox1, oy1, ox2, oy2, oconf = ocr_box
    return yolo_box if yconf > oconf else ocr_box
```

---

## ğŸ–¼ï¸ Ejemplos visuales
![Ejemplo 1](./Captura-readme1.png)
![Ejemplo 2](./Captura-readme2.png)

# Enlace al vÃ­deo (haz clic sobre el para redirigirte al video)

[![Ver demo](https://img.youtube.com/vi/gq9PvOOwxQs/0.jpg)](https://youtu.be/gq9PvOOwxQs)

Se hace blurr bien en las personas y en las matrÃ­culas detectadas

---

## ğŸ§¾ Notas finales
Este notebook constituye la parte principal del pipeline de visiÃ³n de la prÃ¡ctica, y puede combinarse con el mÃ³dulo VC_P4b para tareas de OCR avanzado y mÃ©tricas.  
Ambos mÃ³dulos conforman el flujo completo de detecciÃ³n, anonimizaciÃ³n y anÃ¡lisis de matrÃ­culas.
