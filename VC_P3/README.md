# Pr√°ctica 3 - Visi√≥n por Computador

Este documento recoge el desarrollo de la tercera pr√°ctica de la asignatura **Visi√≥n por Computador**.  
La pr√°ctica se centra en la **detecci√≥n y reconocimiento de formas**, con dos tareas principales: identificaci√≥n de monedas y clasificaci√≥n de micropl√°sticos utilizando t√©cnicas de procesamiento de im√°genes.

---

## Autores
- *Alberto Jos√© Rodr√≠guez Ruano*  
- *Miguel √Ångel Rodr√≠guez Ruano* 

---

## Tarea 1 - Identificaci√≥n y Conteo de Monedas con Diferenciaci√≥n por Color

### Objetivo
Desarrollar un sistema que permita determinar la cantidad de dinero presente en una imagen mediante:
1. **Detecci√≥n autom√°tica** de todas las monedas presentes
2. **Selecci√≥n interactiva** de una moneda de referencia (1‚Ç¨) mediante clic
3. **Clasificaci√≥n por valor** utilizando an√°lisis de tama√±o y color
4. **C√°lculo del valor total** en euros y c√©ntimos
5. **Visualizaci√≥n diferenciada** por color seg√∫n el valor de las monedas

### Metodolog√≠a Implementada

#### 1. Detecci√≥n de C√≠rculos con Transformada de Hough
Se utiliza la transformada de Hough para detectar c√≠rculos (monedas) en la imagen:

```python
# Preprocesamiento de la imagen
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img_blurred = cv2.medianBlur(img_gray, 5)  # Reduce ruido

# Detecci√≥n de c√≠rculos usando Hough
circles = cv2.HoughCircles(
    img_blurred, cv2.HOUGH_GRADIENT, 1, 100, 
    param1=100, param2=50, minRadius=10, maxRadius=150
)
circles = np.uint16(np.around(circles)) if circles is not None else None
```

#### 2. Interfaz de Selecci√≥n por Clic
Sistema interactivo para selecci√≥n de moneda de referencia mediante clic del rat√≥n:

```python
# Funci√≥n callback para detectar clic en moneda
def select_reference_coin(event, x, y, flags, params):
    global reference_coin
    if event == cv2.EVENT_LBUTTONDOWN and circles is not None:
        for idx, (cx, cy, r) in enumerate(circles[0, :]):
            if np.hypot(x - cx, y - cy) <= r:
                reference_coin = (cx, cy, r)
                # Marcar moneda seleccionada
                cv2.circle(display_img, (int(cx), int(cy)), int(r), (0, 0, 255), 3)
                cv2.putText(display_img, "1 Euro", (int(cx - 40), int(cy - r - 10)),
                            cv2.FONT_HERSHEY_TRIPLEX, 0.8, (0, 0, 255), 2)
                return

# Configurar ventana interactiva
cv2.namedWindow("clica en la moneda de 1‚Ç¨", cv2.WINDOW_NORMAL)
cv2.setMouseCallback("clica en la moneda de 1‚Ç¨", select_reference_coin)
```

#### 3. Establecimiento de Escala
C√°lculo de correspondencia p√≠xeles-mil√≠metros usando moneda de 1‚Ç¨:

```python
# Diametros conocidos de las monedas en mil√≠metros
COIN_DIAMETERS_MM = {
    1: 16.25,    # 1 c√©ntimo
    2: 18.75,    # 2 c√©ntimos  
    5: 21.25,    # 5 c√©ntimos
    10: 19.75,   # 10 c√©ntimos
    20: 22.25,   # 20 c√©ntimos
    50: 24.25,   # 50 c√©ntimos
    100: 23.25,  # 1 euro
    200: 25.75   # 2 euros
}

# C√°lculo de tama√±o real basado en referencia
radius_mm = r / reference_coin[2] * COIN_DIAMETERS_MM[100]
```

#### 4. Clasificaci√≥n Multimodal (Tama√±o + Color)
An√°lisis combinado para identificaci√≥n precisa usando valores HSV:

```python
# Funci√≥n de an√°lisis de color en espacio HSV
def analyze_coin_color(x, y, patch_size=5):
    # Extrae parche de la imagen HSV y calcula promedio
    patch = img_hsv[y1:y2, x1:x2]
    mean_hsv = np.mean(patch, axis=(0, 1))
    h, s, v = mean_hsv  # OpenCV HSV: H 0-180, S/V 0-255
    
    # Normalizaci√≥n: h a 0-360¬∞, s y v a 0-1
    h = h * 2
    s = s / 255.0
    v = v / 255.0
    
    # Clasificaci√≥n por rangos HSV
    if s < 0.25:
        return "SILVER"  # Monedas plateadas (1‚Ç¨, 2‚Ç¨)
    elif 0 < h < 70 and s > 0.2 and v > 0.2:
        if h < 35:
            return "COPPER"  # Monedas cobrizas (1c, 2c, 5c)
        else:
            return "GOLD"    # Monedas doradas (10c, 20c, 50c)
    else:
        return "UNKNOWN"

# Grupos de monedas por color
COPPER_COINS = [1, 2, 5]      # Monedas cobrizas
GOLD_COINS = [10, 20, 50]     # Monedas doradas  
SILVER_COINS = [100, 200]     # Monedas plateadas/bimet√°licas
```

#### 5. Visualizaci√≥n con C√≥digos de Color
Sistema de diferenciaci√≥n visual seg√∫n valor de las monedas:

```python
# Asignaci√≥n de colores seg√∫n valor de las monedas
for idx, value, color in final_classifications:
    cx, cy, r = circles[0, idx - 1]
    
    # Colores de bordes seg√∫n grupo de valor
    if value in [1, 2, 5]:        # Monedas de bajo valor
        border_color = (0, 255, 255)  # Amarillo
    elif value in [10, 20, 50]:   # Monedas de valor medio
        border_color = (255, 0, 0)    # Azul  
    elif value in [100, 200]:     # Monedas de alto valor
        border_color = (0, 0, 255)    # Rojo

    # Dibujar c√≠rculo y etiquetas
    cv2.circle(img_final, (int(cx), int(cy)), int(r), border_color, 3)
    label = f"{value//100}eu" if value >= 100 else f"{value}ct"
    text = f"{label}  |  {color[:3]}  |  {radius_mm:.1f}mm"
```

### Caracter√≠sticas T√©cnicas

**Par√°metros de Detecci√≥n:**
- M√©todo: Transformada de Hough para c√≠rculos
- Par√°metros HoughCircles: dp=1, minDist=100, param1=100, param2=50
- Rango de radios: 10-150 p√≠xeles
- Resoluci√≥n de acumulador: 1 p√≠xel

**An√°lisis de Color:**
- Espacio HSV para robustez ante iluminaci√≥n
- Tama√±o de parche inicial: 5x5 p√≠xeles
- Tama√±o de parche ampliado: 10x10 p√≠xeles
- Puntos de muestreo: centro + 4 puntos radiales a 90% del radio

**Interfaz de Usuario:**
- Selecci√≥n por clic del rat√≥n en la moneda de 1‚Ç¨
- Ventana OpenCV redimensionable
- Feedback visual inmediato con c√≠rculo rojo
- Destrucci√≥n autom√°tica de ventanas

### Resultados Obtenidos

A continuaci√≥n se presentan los resultados obtenidos tras aplicar el sistema de detecci√≥n y clasificaci√≥n de monedas sobre tres im√°genes diferentes, con condiciones de iluminaci√≥n y calidad variables.

#### Caso 1: Imagen en condiciones controladas

La primera imagen se tom√≥ en un entorno controlado, con fondo blanco y buena iluminaci√≥n.
El sistema detecta correctamente todas las monedas y clasifica de forma precisa tanto su valor como su color.

![Resultados con fondo blanco](Resultado%20monedas.png)

---

#### Caso 2: Imagen tomada con el m√≥vil (sombras y reflejos pronunciados)

En esta captura, realizada con la c√°mara del m√≥vil, aparecen **sombras y reflejos** que dificultan la segmentaci√≥n y el an√°lisis de color.
El sistema muestra varios errores de clasificaci√≥n, confundiendo algunas monedas de diferente color y valor.

![Resultados con sombras y reflejos - fallos](Resultado%20monedas%202.png)

---

#### Caso 3: Imagen m√≥vil con sombras moderadas

En esta imagen tambi√©n existen sombras y reflejos.
El sistema logra **clasificar correctamente la mayor√≠a de las monedas**, fallando √∫nicamente en una, lo que demuestra una buena **robustez ante variaciones lum√≠nicas**.

![Resultados con sombras moderadas - aciertos](Resultado%20monedas%203.png)

## Tarea 2 - Clasificaci√≥n de Micropl√°sticos mediante Caracter√≠sticas Geom√©tricas

### Objetivo

El prop√≥sito de esta segunda tarea es desarrollar un sistema de **clasificaci√≥n autom√°tica de micropl√°sticos** a partir de las 3 im√°genes proporcionadas, utilizando **caracter√≠sticas geom√©tricas y visuales** extra√≠das de las part√≠culas observadas.  
El sistema debe ser capaz de aprender patrones de tres tipos de part√≠culas ‚Äî**fragmentos (FRA)**, **pellets (PEL)** y **alquitr√°n (TAR)**‚Äî y posteriormente **clasificar objetos desconocidos** en una imagen de test (*MPs_test.jpg*), evaluando su desempe√±o mediante m√©tricas est√°ndar y una **matriz de confusi√≥n**.

---

### Metodolog√≠a Implementada

#### 1. Extracci√≥n de M√°scaras Binarias

Para segmentar las part√≠culas se emplea un proceso robusto basado en:
- **Ecualizaci√≥n adaptativa del canal de luminancia (CLAHE)** para compensar iluminaci√≥n no uniforme.  
- **Umbralizaci√≥n adaptativa** (m√©todo de Gauss) para aislar regiones relevantes.  
- **Operaciones morfol√≥gicas** (cerrado y apertura el√≠ptica) para limpiar ruido.  
- **Relleno de agujeros** mediante *flood fill*.

```python
def build_binary_mask(img_bgr, morph_kernel_size=5):
    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8,8))
    l_eq = clahe.apply(l)
    img_eq = cv2.cvtColor(cv2.merge([l_eq, a, b]), cv2.COLOR_LAB2BGR)
    blur = cv2.bilateralFilter(cv2.cvtColor(img_eq, cv2.COLOR_BGR2GRAY), 9, 75, 75)
    mask = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                 cv2.THRESH_BINARY_INV, 35, 5)
    # Refinado morfol√≥gico
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_kernel_size, morph_kernel_size))
    mask_clean = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_OPEN, kernel)
    flood = mask_clean.copy()
    h,w = flood.shape[:2]
    mask_ff = np.zeros((h+2,w+2), np.uint8)
    cv2.floodFill(flood, mask_ff, (0,0), 255)
    mask_final = mask_clean | cv2.bitwise_not(flood)
    return img_eq, mask_final
```

#### 2. Detecci√≥n y Filtrado de Contornos
Filtrado por √°rea e intersecci√≥n (IoU) para eliminar solapamientos y ruido.
```python
ef detectar_contornos_validos(img, min_area=300, max_area=10000, solapamiento_minimo=True):
    """Detecta contornos v√°lidos usando build_binary_mask y filtrado posterior"""
    img_eq, mask = build_binary_mask(img)
    contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = [c for c in contours if min_area <= cv2.contourArea(c) <= max_area]

    to_remove = set()
    for i in range(len(contours)):
        for j in range(i+1,len(contours)):
            val = iou_boxes(cv2.boundingRect(contours[i]), cv2.boundingRect(contours[j]))
            if val>0:
                if cv2.contourArea(contours[i]) < cv2.contourArea(contours[j]): 
                    to_remove.add(i)
                else: 
                    to_remove.add(j)

    return [c for k,c in enumerate(contours) if k not in to_remove]
```

#### 3. Extracci√≥n de Caracter√≠sticas
Ocho descriptores geom√©tricos y visuales basados en el trabajo *SMACC (2020)*: √°rea, per√≠metro, compacidad, relaci√≥n √°rea/rect√°ngulo, aspecto, ejes, distancias al centroide y intensidad media de color respecto al negro (para textura/coloraci√≥n).
```python
def extraer_features_contornos(img, contours):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    features, rects = [], []
    for c in contours:
        area = cv2.contourArea(c)
        if area==0: continue
        perimetro = cv2.arcLength(c, True)
        x,y,w,h = cv2.boundingRect(c)
        rel_aspecto = w/h if h else 0
        rel_area_cont = area/(w*h) if w*h else 0
        compact = (perimetro**2)/(4*np.pi*area)
        rel_ejes = 0
        if len(c)>=5:
            try: (xc,yc),(MA,ma),ang=cv2.fitEllipse(c); rel_ejes=ma/MA if MA else 0
            except: rel_ejes=0
        M = cv2.moments(c)
        cx,cy=(int(M["m10"]/M["m00"]), int(M["m01"]/M["m00"])) if M["m00"] else (0,0)
        dists=[np.linalg.norm(np.array([cx,cy])-pt[0]) for pt in c]
        rel_dist_centroid=min(dists)/max(dists) if dists and max(dists)!=0 else 0
        mask_obj = np.zeros(gray.shape,np.uint8)
        cv2.drawContours(mask_obj,[c],-1,255,-1)
        mean_color = cv2.mean(img, mask=mask_obj)[:3]
        black_dist = np.linalg.norm(np.array(mean_color)-np.array([0,0,0]))
        features.append([area, perimetro, compact, rel_area_cont,
                         rel_aspecto, rel_ejes, rel_dist_centroid, black_dist])
        rects.append((x,y,w,h))
    return np.array(features), rects
```

#### 4. Entrenamiento y Clasificaci√≥n
Se construye un conjunto de entrenamiento a partir de tres im√°genes, una por clase:

- *FRA*: fragmentos irregulares

- *PEL*: pellets esf√©ricos

- *TAR*: part√≠culas oscuras o alquitranadas

Para cada clase, se calculan las caracter√≠sticas de sus part√≠culas y se normalizan (Œº, œÉ).
La clasificaci√≥n de nuevos objetos se realiza mediante una distancia eucl√≠dea ponderada, donde cada caracter√≠stica contribuye con un peso distinto en funci√≥n de su relevancia emp√≠rica:

| Feature | Peso |
|----------|------|
| √Årea | 3.5 |
| Per√≠metro | 2.4 |
| Compacidad | 4.5 |
| Relaci√≥n √°rea/rect√°ngulo | 2.25 |
| Relaci√≥n de aspecto | 3.5 |
| Relaci√≥n entre ejes | 4.0 |
| Relaci√≥n distancias al centroide | 5.3 |
| Distancia al negro | 3.5 |

---

### Resultados Obtenidos

#### Entrenamiento - Detecci√≥n de Objetos y Extracci√≥n de Caracter√≠sticas
![Detecci√≥n FRA](entrenamiento-fra.png)  
![Detecci√≥n PELLET](entrenamiento-pel.png)  
![Detecci√≥n TAR](entrenamiento-tar.png)

#### Clasificaci√≥n sobre Imagen de Test
![Clasificaci√≥n test](objetos-detectados-test.png)

#### M√©tricas y Matriz de Confusi√≥n

**Resultados globales:**  
- Accuracy = 0.8226
- Precision = 0.8685
- Recall = 0.8100
- F1=0.8290

![Matriz de confusi√≥n](matriz-confusi√≥n.png)

---

### Conclusiones
El sistema logr√≥ una **tasa de acierto superior al 82%**, mostrando especial precisi√≥n en la clasificaci√≥n de **fragmentos (FRA)**, mientras que las part√≠culas tipo **TAR** y **pellets (PEL)** presentan mayor confusi√≥n. 
El pipeline demuestra la eficacia de combinar **caracter√≠sticas geom√©tricas simples** con una **clasificaci√≥n ponderada** para la identificaci√≥n autom√°tica de micropl√°sticos.

## Instalaci√≥n y requisitos

Para ejecutar esta pr√°ctica es necesario tener instalado **Python 3.8 o superior** y **Jupyter Notebook**.
Adem√°s, deben instalarse las siguientes librer√≠as:

```bash
pip install opencv-python numpy matplotlib pandas seaborn scikit-learn
```

> üí° Se recomienda el uso de un entorno virtual (`venv` o `conda`) para evitar conflictos de dependencias.

**Requisitos adicionales por tarea:**

* **Tarea 1 (Monedas):**
  Paquetes principales:

  ```python
  import cv2
  import numpy as np
  import matplotlib.pyplot as plt
  import csv
  from collections import Counter
  ```

* **Tarea 2 (Micropl√°sticos):** 
  Paquetes adicionales:

  ```python
  import pandas as pd
  import seaborn as sns
  from sklearn.preprocessing import StandardScaler
  from sklearn.ensemble import RandomForestClassifier
  from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score
  ```

---

## Fuentes

* [Documentaci√≥n de OpenCV](https://docs.opencv.org/)
* [Documentaci√≥n de NumPy](https://numpy.org/doc/)
* [Documentaci√≥n de Matplotlib](https://matplotlib.org/stable/contents.html)
* [Documentaci√≥n de scikit-learn](https://scikit-learn.org/stable/)
* **SMACC: A System for Microplastics Automatic Counting and Classification** ‚Äî referencia metodol√≥gica para la segunda tarea
* Ejemplos base proporcionados por el profesorado en la Pr√°ctica 3 de VC
* *GitHub Copilot*
* *ChatGPT (OpenAI GPT-5)*

