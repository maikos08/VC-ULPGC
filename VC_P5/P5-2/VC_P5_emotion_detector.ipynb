{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29423e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Pulsa 'q' para salir\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "\n",
    "# ============================\n",
    "# CONFIG GENERAL\n",
    "# ============================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "class_names = [\"angry\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# ============================\n",
    "# MODELO RESNET50 EMOCIONES\n",
    "# ============================\n",
    "\n",
    "def get_model(num_classes=6):\n",
    "    base = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    num_ftrs = base.fc.in_features  # 2048\n",
    "\n",
    "    base.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_ftrs, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "\n",
    "    for name, param in base.named_parameters():\n",
    "        if 'layer1' in name or 'layer2' in name:\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return base\n",
    "\n",
    "model = get_model(num_classes=len(class_names)).to(device)\n",
    "state_dict = torch.load(\"best_model_emotions.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_emotion(face_bgr):\n",
    "    face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)\n",
    "    tensor = transform(face_rgb)\n",
    "    tensor = tensor.unsqueeze(0).to(device)\n",
    "    logits = model(tensor)\n",
    "    probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    idx = int(np.argmax(probs))\n",
    "    return class_names[idx], probs\n",
    "\n",
    "# ============================\n",
    "# FONDOS POR EMOCIÓN\n",
    "# ============================\n",
    "\n",
    "def draw_emotion_background(frame, label):\n",
    "    h, w, _ = frame.shape\n",
    "    overlay = np.zeros_like(frame)\n",
    "\n",
    "    if label == \"happy\":\n",
    "        for i in range(h):\n",
    "            alpha = i / h\n",
    "            color = (\n",
    "                int(255 * (1 - alpha) + 200 * alpha),\n",
    "                int(255 * (1 - alpha) + 220 * alpha),\n",
    "                int(200 * (1 - alpha) + 150 * alpha)\n",
    "            )\n",
    "            overlay[i, :] = color\n",
    "\n",
    "        center = (w - 100, 100)\n",
    "        cv2.circle(overlay, center, 50, (0, 255, 255), -1)\n",
    "        for angle in range(0, 360, 30):\n",
    "            x2 = int(center[0] + 80 * np.cos(np.deg2rad(angle)))\n",
    "            y2 = int(center[1] + 80 * np.sin(np.deg2rad(angle)))\n",
    "            cv2.line(overlay, center, (x2, y2), (0, 255, 255), 3)\n",
    "        for cx, cy in [(120, 120), (220, 80), (80, 80)]:\n",
    "            cv2.ellipse(overlay, (cx, cy), (60, 30), 0, 0, 360, (255, 255, 255), -1)\n",
    "            cv2.ellipse(overlay, (cx+30, cy+10), (50, 25), 0, 0, 360, (255, 255, 255), -1)\n",
    "\n",
    "    elif label == \"sad\":\n",
    "        for i in range(h):\n",
    "            alpha = i / h\n",
    "            color = (\n",
    "                int(100 * (1 - alpha) + 50 * alpha),\n",
    "                int(100 * (1 - alpha) + 80 * alpha),\n",
    "                int(140 * (1 - alpha) + 160 * alpha)\n",
    "            )\n",
    "            overlay[i, :] = color\n",
    "\n",
    "        for cx, cy in [(w//4, 80), (w//2, 60), (3*w//4, 90)]:\n",
    "            cv2.ellipse(overlay, (cx, cy), (120, 40), 0, 0, 360, (80, 80, 90), -1)\n",
    "\n",
    "        for x in range(0, w, 20):\n",
    "            y_start = np.random.randint(0, 50)\n",
    "            y_end = y_start + np.random.randint(30, 80)\n",
    "            cv2.line(overlay, (x, y_start), (x+5, y_end), (200, 200, 255), 1)\n",
    "\n",
    "        for _ in range(20):\n",
    "            cx = np.random.randint(0, w)\n",
    "            cy = np.random.randint(h//2, h)\n",
    "            cv2.circle(overlay, (cx, cy), 3, (230, 230, 255), -1)\n",
    "\n",
    "    elif label == \"angry\":\n",
    "        for i in range(h):\n",
    "            alpha = i / h\n",
    "            color = (\n",
    "                int(0 * (1 - alpha) + 0 * alpha),\n",
    "                int(0 * (1 - alpha) + 50 * alpha),\n",
    "                int(100 * (1 - alpha) + 255 * alpha)\n",
    "            )\n",
    "            overlay[i, :] = color\n",
    "\n",
    "        for _ in range(80):\n",
    "            base_x = np.random.randint(0, w)\n",
    "            height = np.random.randint(40, 120)\n",
    "            pts = np.array([\n",
    "                (base_x, h),\n",
    "                (base_x + np.random.randint(-20, 20), h - height),\n",
    "                (base_x + np.random.randint(-40, 40), h)\n",
    "            ], np.int32)\n",
    "            cv2.fillConvexPoly(overlay, pts,\n",
    "                               (0, np.random.randint(100, 180), 255))\n",
    "\n",
    "    elif label == \"fear\":\n",
    "        for i in range(h):\n",
    "            alpha = i / h\n",
    "            color = (\n",
    "                int(40 * (1 - alpha) + 20 * alpha),\n",
    "                int(40 * (1 - alpha) + 0 * alpha),\n",
    "                int(80 * (1 - alpha) + 120 * alpha)\n",
    "            )\n",
    "            overlay[i, :] = color\n",
    "\n",
    "        fog = overlay.copy()\n",
    "        for _ in range(40):\n",
    "            cx = np.random.randint(0, w)\n",
    "            cy = np.random.randint(0, h)\n",
    "            r = np.random.randint(30, 80)\n",
    "            cv2.circle(fog, (cx, cy), r, (80, 80, 120), -1)\n",
    "        cv2.addWeighted(fog, 0.3, overlay, 0.7, 0, overlay)\n",
    "\n",
    "        center = (w//2, h//3)\n",
    "        cv2.ellipse(overlay, center, (60, 25), 0, 0, 360, (200, 200, 220), 2)\n",
    "        cv2.circle(overlay, center, 8, (200, 200, 220), -1)\n",
    "\n",
    "    elif label == \"surprise\":\n",
    "        overlay[:] = (30, 30, 30)\n",
    "        center = (w//2, h//2)\n",
    "        for angle in range(0, 360, 10):\n",
    "            length = np.random.randint(80, 200)\n",
    "            x2 = int(center[0] + length * np.cos(np.deg2rad(angle)))\n",
    "            y2 = int(center[1] + length * np.sin(np.deg2rad(angle)))\n",
    "            cv2.line(overlay, center, (x2, y2), (255, 255, 255), 1)\n",
    "        for _ in range(80):\n",
    "            rx = np.random.randint(0, w)\n",
    "            ry = np.random.randint(0, h)\n",
    "            color = (\n",
    "                np.random.randint(200, 255),\n",
    "                np.random.randint(200, 255),\n",
    "                np.random.randint(200, 255)\n",
    "            )\n",
    "            cv2.circle(overlay, (rx, ry), 2, color, -1)\n",
    "\n",
    "    else:  # neutral\n",
    "        for i in range(h):\n",
    "            alpha = i / h\n",
    "            color = (\n",
    "                int(160 * (1 - alpha) + 120 * alpha),\n",
    "                int(160 * (1 - alpha) + 160 * alpha),\n",
    "                int(170 * (1 - alpha) + 180 * alpha)\n",
    "            )\n",
    "            overlay[i, :] = color\n",
    "\n",
    "    cv2.addWeighted(overlay, 0.9, frame, 0.1, 0, frame)\n",
    "\n",
    "# ============================\n",
    "# BUCLE WEBCAM + DEEPFACE (opencv)\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"No se pudo abrir la webcam\")\n",
    "        return\n",
    "\n",
    "    print(\"Pulsa 'q' para salir\")\n",
    "    prev_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        orig_frame = frame.copy()\n",
    "\n",
    "        label = \"neutral\"\n",
    "        face_box = None\n",
    "\n",
    "        # 1. Detección de cara con DeepFace (backend opencv) [web:103][web:95]\n",
    "        try:\n",
    "            detections = DeepFace.extract_faces(\n",
    "                img_path=orig_frame,\n",
    "                detector_backend=\"opencv\",\n",
    "                enforce_detection=False\n",
    "            )\n",
    "            if len(detections) > 0:\n",
    "                det = detections[0]\n",
    "                fa = det[\"facial_area\"]\n",
    "                x, y, w, h = fa[\"x\"], fa[\"y\"], fa[\"w\"], fa[\"h\"]\n",
    "\n",
    "                # clamp a la imagen\n",
    "                x = max(0, x)\n",
    "                y = max(0, y)\n",
    "                w = max(1, min(w, orig_frame.shape[1] - x))\n",
    "                h = max(1, min(h, orig_frame.shape[0] - y))\n",
    "\n",
    "                face_box = (x, y, w, h)\n",
    "                face_bgr = orig_frame[y:y+h, x:x+w]\n",
    "                label, probs = predict_emotion(face_bgr)\n",
    "        except Exception:\n",
    "            label = \"neutral\"\n",
    "            face_box = None\n",
    "\n",
    "        # 2. Pintar fondo según emoción\n",
    "        draw_emotion_background(frame, label)\n",
    "\n",
    "        # 3. Volver a poner la cara original encima del fondo\n",
    "        if face_box is not None:\n",
    "            x, y, w, h = face_box\n",
    "            face_roi = orig_frame[y:y+h, x:x+w]\n",
    "            frame[y:y+h, x:x+w] = face_roi\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255,255,255), 2)\n",
    "\n",
    "        # 4. Texto emoción y FPS\n",
    "        cv2.putText(frame, label, (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        now = time.time()\n",
    "        fps = 1.0 / (now - prev_time + 1e-6)\n",
    "        prev_time = now\n",
    "        cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"Emotion Backgrounds (DeepFace OpenCV)\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5_emotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
