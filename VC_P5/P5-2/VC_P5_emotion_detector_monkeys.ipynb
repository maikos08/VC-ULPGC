{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfec704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Webcam iniciada - Modo LADO A LADO con tu modelo\n",
      "Presiona 'q' para salir\n",
      "Finalizado\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from deepface import DeepFace\n",
    "from collections import deque, Counter\n",
    "import time\n",
    "\n",
    "# ============================\n",
    "# CONFIG GENERAL\n",
    "# ============================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "class_names = [\"angry\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "\n",
    "# Mapeo emociones del modelo -> nombres de archivos mono\n",
    "emotion_to_mono = {\n",
    "    \"angry\": \"enfadado\",\n",
    "    \"fear\": \"sorprendido\",\n",
    "    \"happy\": \"feliz\",\n",
    "    \"neutral\": \"neutral\",\n",
    "    \"sad\": \"pensando\",\n",
    "    \"surprise\": \"sorprendido\"\n",
    "}\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# ============================\n",
    "# MODELO RESNET50 EMOCIONES\n",
    "# ============================\n",
    "\n",
    "def get_model(num_classes=6):\n",
    "    base = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    num_ftrs = base.fc.in_features\n",
    "\n",
    "    base.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_ftrs, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "\n",
    "    for name, param in base.named_parameters():\n",
    "        if 'layer1' in name or 'layer2' in name:\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return base\n",
    "\n",
    "model = get_model(num_classes=len(class_names)).to(device)\n",
    "state_dict = torch.load(\"best_model_emotions.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_emotion(face_bgr):\n",
    "    face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)\n",
    "    tensor = transform(face_rgb)\n",
    "    tensor = tensor.unsqueeze(0).to(device)\n",
    "    logits = model(tensor)\n",
    "    probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    idx = int(np.argmax(probs))\n",
    "    return class_names[idx], probs\n",
    "\n",
    "# ============================\n",
    "# CARGAR IMÁGENES DE MONOS\n",
    "# ============================\n",
    "\n",
    "monos = {\n",
    "    'neutral': cv2.imread('../images/mono_neutral.webp'),\n",
    "    'feliz': cv2.imread('../images/mono_feliz.png'),\n",
    "    'sorprendido': cv2.imread('../images/mono_sorprendido.jpg'),\n",
    "    'pensando': cv2.imread('../images/mono_pensando.jpg'),\n",
    "    'enfadado': cv2.imread('../images/mono_enfadado.jpg')\n",
    "}\n",
    "\n",
    "for nombre, img in monos.items():\n",
    "    if img is None:\n",
    "        print(f\"AVISO: No se pudo cargar images/mono_{nombre}\")\n",
    "\n",
    "# ============================\n",
    "# FUNCIÓN REDIMENSIONAR\n",
    "# ============================\n",
    "\n",
    "def redimensionar_imagen(img, alto_objetivo):\n",
    "    \"\"\"Redimensiona imagen manteniendo aspect ratio\"\"\"\n",
    "    if img is None:\n",
    "        return None\n",
    "    h, w = img.shape[:2]\n",
    "    ratio = alto_objetivo / h\n",
    "    nuevo_ancho = int(w * ratio)\n",
    "    return cv2.resize(img, (nuevo_ancho, alto_objetivo))\n",
    "\n",
    "# ============================\n",
    "# BUCLE WEBCAM LADO A LADO\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: No se pudo abrir la webcam\")\n",
    "        return\n",
    "\n",
    "    print(\"Webcam iniciada - Modo LADO A LADO con tu modelo\")\n",
    "    print(\"Presiona 'q' para salir\")\n",
    "\n",
    "    historial = deque(maxlen=5)\n",
    "    prev_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        orig_frame = frame.copy()\n",
    "        annotated_frame = frame.copy()\n",
    "\n",
    "        label = \"neutral\"\n",
    "        face_box = None\n",
    "\n",
    "        # 1. Detección de cara con DeepFace\n",
    "        try:\n",
    "            detections = DeepFace.extract_faces(\n",
    "                img_path=orig_frame,\n",
    "                detector_backend=\"opencv\",\n",
    "                enforce_detection=False\n",
    "            )\n",
    "            if len(detections) > 0:\n",
    "                det = detections[0]\n",
    "                fa = det[\"facial_area\"]\n",
    "                x, y, w, h = fa[\"x\"], fa[\"y\"], fa[\"w\"], fa[\"h\"]\n",
    "\n",
    "                x = max(0, x)\n",
    "                y = max(0, y)\n",
    "                w = max(1, min(w, orig_frame.shape[1] - x))\n",
    "                h = max(1, min(h, orig_frame.shape[0] - y))\n",
    "\n",
    "                face_box = (x, y, w, h)\n",
    "                face_bgr = orig_frame[y:y+h, x:x+w]\n",
    "                label, probs = predict_emotion(face_bgr)\n",
    "\n",
    "                # Dibujar rectángulo de detección\n",
    "                cv2.rectangle(annotated_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        except Exception:\n",
    "            label = \"neutral\"\n",
    "            face_box = None\n",
    "\n",
    "        # 2. Suavizado temporal\n",
    "        historial.append(label)\n",
    "        label_suavizado = Counter(historial).most_common(1)[0][0]\n",
    "\n",
    "        # 3. Texto con estado y FPS\n",
    "        cv2.putText(annotated_frame, f\"Estado: {label_suavizado.upper()}\",\n",
    "                    (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "\n",
    "        now = time.time()\n",
    "        fps = 1.0 / (now - prev_time + 1e-6)\n",
    "        prev_time = now\n",
    "        cv2.putText(annotated_frame, f\"FPS: {fps:.1f}\",\n",
    "                    (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # 4. Obtener mono y redimensionar\n",
    "        mono_key = emotion_to_mono.get(label_suavizado, \"neutral\")\n",
    "        mono_img = monos.get(mono_key, monos.get('neutral'))\n",
    "\n",
    "        altura_frame = annotated_frame.shape[0]\n",
    "        mono_resized = redimensionar_imagen(mono_img, altura_frame)\n",
    "\n",
    "        # 5. Combinar lado a lado\n",
    "        if mono_resized is not None:\n",
    "            combined = np.hstack((annotated_frame, mono_resized))\n",
    "        else:\n",
    "            combined = annotated_frame\n",
    "\n",
    "        cv2.imshow('Espejo con el mono (Modelo propio)', combined)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5_emotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
