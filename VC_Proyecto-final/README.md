# Trabajo Final ‚Äî **Sistema autom√°tico de c√°mara inteligente**

## *Sistema Aut√≥nomo de Encuadre Cinematogr√°fico con Visi√≥n por Computador*

![Car√°tula](./caratula.jpg)

---

## üë• Autores
- **Alberto Jos√© Rodr√≠guez Ruano**  
- **Miguel √Ångel Rodr√≠guez Ruano**

---

## Objetivo del proyecto

Este **trabajo final** desarrolla un **sistema de encuadre cinematogr√°fico inteligente en tiempo real**, capaz de analizar la **pose corporal, los gestos de mano y la orientaci√≥n del sujeto** para tomar decisiones autom√°ticas de c√°mara inspiradas en el **lenguaje cinematogr√°fico cl√°sico**.

El sistema act√∫a como un **operador de c√°mara virtual**, decidiendo de forma aut√≥noma:

* el **tipo de plano** m√°s adecuado (general, medio, primer plano, etc.)
* el **centro de seguimiento** del sujeto
* el **nivel de zoom**
* el **desplazamiento vertical del encuadre**
* la **estabilidad narrativa** mediante suavizado temporal y bloqueo (hold)

Todo ello se ejecuta **en tiempo real**, usando modelos **preentrenados de MediaPipe**, sin entrenamiento propio.

---

## Concepto general

Traduce informaci√≥n f√≠sica del sujeto en **decisiones narrativas de c√°mara**.

El sistema combina:

* Visi√≥n por computador
* Heur√≠sticas cinematogr√°ficas
* Interacci√≥n humano-m√°quina (gestos)
* Suavizado temporal para evitar jitter visual

El resultado es un prototipo funcional orientado a:

* producci√≥n audiovisual automatizada
* streaming
* investigaci√≥n en IA creativa
* herramientas de apoyo a realizaci√≥n

---

## Qu√© hay en este repositorio

* `VC_proyecto.py`
  Script principal del sistema. Contiene:

  * inicializaci√≥n de MediaPipe (pose, manos, cara)
  * sistema completo de clasificaci√≥n de planos
  * detecci√≥n autom√°tica basada en pose
  * control manual por gestos
  * sistema de suavizado y encuadre
  * interfaz visual con tres ventanas
  * soporte multi-c√°mara (selecci√≥n din√°mica de c√°mara activa; no mezcla simult√°nea)
  * captura de screenshots

* `/screenshots/`
  Carpeta creada autom√°ticamente para guardar capturas.

---

## Requisitos

Se recomienda usar un entorno virtual.

Dependencias m√≠nimas est√°n especificadas en el archivo requierements, lo que se deber√≠a hacer es:

```bash
conda create -n camera_intelligent python=3.10
conda activate camera_intelligent

pip install -r requirements.txt
```

Hardware:

* Webcam (720p o superior)
* CPU moderna
* Soporte opcional para **dos c√°maras simult√°neas**

---

## Ejecuci√≥n del sistema

Ejecutar directamente el script:

```bash
python VC_proyecto.py
```

Al iniciarse, el sistema:

1. Detecta c√°maras disponibles (1 o 2)
2. Muestra un resumen completo de planos y controles
3. Abre tres ventanas independientes:

   * **CONTROL**
   * **DETECCI√ìN**
   * **RESULTADO**

---

## Ventanas del sistema

### 1. Ventana DETECCI√ìN

* Muestra el v√≠deo original
* Dibuja:

  * landmarks de pose (MediaPipe Pose)
  * landmarks de manos (MediaPipe Hands)
* √ötil para depuraci√≥n y comprensi√≥n del sistema

---

### 2. Ventana RESULTADO

* Muestra **√∫nicamente el encuadre final**
* Aplica:

  * recorte din√°mico
  * zoom seg√∫n plano
  * suavizado temporal
* No muestra texto ni overlays
* Opcionalmente muestra **grid de composici√≥n (regla de los tercios)**

---

### 3. Ventana CONTROL

Panel lateral que muestra:

* FPS promedio
* n√∫mero de c√°maras
* modo activo (AUTO / MANUAL)
* estado del HOLD
* plano activo y plano detectado autom√°ticamente
* orientaci√≥n corporal (yaw, pitch, roll)
* controles disponibles
* recordatorio de gestos manuales
* estado del grid

---

## Sistema de planos cinematogr√°ficos

El sistema define un **diccionario expl√≠cito de planos**, cada uno con:

* factor de zoom
* nombre cinematogr√°fico
* descripci√≥n narrativa
* offset vertical
* gesto manual asociado (si existe)
* criterio de detecci√≥n autom√°tica

### Planos implementados

* Plano General Extremo
* Plano General
* Plano Entero
* Plano Americano
* Plano Medio
* Plano Medio Corto
* Primer Plano
* Primer√≠simo Primer Plano
* Sobre el Hombro (AUTO)
* Plano de Espaldas (AUTO)
* Picado (AUTO)
* Contrapicado (AUTO)

Este sistema est√° centralizado en la estructura `PLANOS`.

---

## Modos de control

### Modo AUTO (por defecto)

En este modo el sistema decide el plano autom√°ticamente usando:

* ancho relativo de hombros
* visibilidad de caderas, rodillas y tobillos
* posici√≥n del sujeto dentro del frame
* orientaci√≥n corporal (frontal, perfil, espaldas)

La l√≥gica se implementa en la clase:

```python
BodyPositionDetector
```

Incluye:

* detecci√≥n heur√≠stica
* buffer temporal (`deque`)
* suavizado por moda
* modo debug opcional

---

### Modo MANUAL (gestos de mano)

En modo manual, el usuario controla el plano mediante **gestos reconocidos por MediaPipe Hands**.

Gestos implementados:

* üëé Pulgar abajo ‚Üí Plano General Extremo
* ‚úä Pu√±o ‚Üí Plano General
* ‚òùÔ∏è Un dedo ‚Üí Plano Entero
* üññ Cuatro dedos ‚Üí Plano Americano
* ü§ü Tres dedos ‚Üí Plano Medio
* üñêÔ∏è Mano abierta ‚Üí Plano Medio Corto
* ‚úåÔ∏è Paz ‚Üí Primer Plano
* ü§ò Rock & Roll ‚Üí Primer√≠simo Primer Plano

La clasificaci√≥n se realiza mediante:

* conteo de dedos
* detecci√≥n expl√≠cita de gestos especiales

---

## HOLD ‚Äî Bloqueo de encuadre

El sistema permite congelar el plano actual:

* Evita cambios autom√°ticos
* Mantiene estabilidad narrativa
* Funciona tanto en AUTO como MANUAL

Se controla con la tecla:

```
h
```

---

## Seguimiento y suavizado del encuadre

El encuadre no cambia de forma brusca.

El sistema utiliza:

* una clase `SmoothFramer`
* interpolaci√≥n progresiva entre estados
* suavizado configurable

Par√°metros:

* centro X
* centro Y
* zoom

Esto evita jitter y saltos de plano no deseados.

---

## Centro de seguimiento inteligente

El punto de seguimiento cambia seg√∫n el plano:

* Primeros planos ‚Üí rostro
* Planos medios ‚Üí cabeza + hombros
* Planos abiertos ‚Üí centro corporal

Esto se implementa en:

```python
obtener_centro_seguimiento()
```

---

## Orientaci√≥n corporal

Se calcula orientaci√≥n 3D aproximada del torso:

* yaw
* pitch
* roll

Usando hombros y caderas en espacio 3D.

Los valores se:

* suavizan temporalmente
* muestran en el panel de control
* usan para decisiones autom√°ticas (espaldas, perfil)

---

## Captura de screenshots

El sistema permite guardar el resultado final:

* tecla `s`
* guarda en `/screenshots`
* incluye:

  * timestamp
  * nombre del plano

---

## Controles del sistema

* `m` ‚Üí cambiar AUTO / MANUAL
* `h` ‚Üí activar/desactivar HOLD
* `s` ‚Üí screenshot
* `g` ‚Üí mostrar/ocultar grid
* `c` ‚Üí cambiar c√°mara activa
* `r` ‚Üí reset del sistema
* `ESC` ‚Üí salir

---

## Bloques hechos para poder llegar al producto final

### üî∑ Bloque 1: Configuraci√≥n Inicial y Detecci√≥n B√°sica

**Objetivo**: Establecer la base del sistema con MediaPipe y detecci√≥n simple de landmarks corporales.

**Componentes**:
* Inicializaci√≥n de MediaPipe Pose
* Captura de video en tiempo real
* Visualizaci√≥n b√°sica de landmarks (33 puntos del cuerpo)
* Frame √∫nico con detecci√≥n sin procesamiento adicional

**Tecnolog√≠as**: `mediapipe`, `opencv-python`, `numpy`

**Lo que aprender√°s**: C√≥mo MediaPipe detecta la pose humana y representa el cuerpo mediante coordenadas 3D normalizadas.

![Bloque 1 - Detecci√≥n B√°sica](./gif1.gif)

---

### üî∑ Bloque 2: An√°lisis de Distancia y Detecci√≥n Autom√°tica de Planos

**Objetivo**: Clasificar autom√°ticamente el tipo de plano cinematogr√°fico seg√∫n la distancia del sujeto a la c√°mara.

**Componentes**:
* Clase `DetectorPlanos` con heur√≠sticas de clasificaci√≥n
* C√°lculo del **ancho de hombros** como m√©trica principal
* An√°lisis de **visibilidad de partes del cuerpo** (caderas, rodillas, tobillos)
* Sistema de **suavizado temporal** mediante buffer hist√≥rico
* 7 planos cinematogr√°ficos: desde *Extreme Wide* hasta *Extreme Close-up*
* Interfaz con **grid de composici√≥n** (regla de tercios)

**Lo que aprender√°s**: C√≥mo traducir m√©tricas corporales (ancho de hombros, visibilidad de landmarks) en decisiones cinematogr√°ficas autom√°ticas.

![Bloque 2 - Detecci√≥n Autom√°tica](./gif2.gif)
---

### üî∑ Bloque 3: Control Manual con Gestos de Mano

**Objetivo**: A√±adir control interactivo mediante reconocimiento de gestos manuales.

**Componentes**:
* Integraci√≥n de **MediaPipe Hands** para detecci√≥n de manos
* Clasificaci√≥n de **8 gestos espec√≠ficos**: pu√±o cerrado, dedos levantados, paz, rock, pulgar abajo
* L√≥gica de **conteo de dedos** y detecci√≥n de gestos especiales
* Cambio de plano en tiempo real seg√∫n el gesto reconocido
* Panel lateral con **lista de gestos disponibles**

**Gestos implementados**:
* ‚úä Pu√±o ‚Üí Plano General
* ‚òùÔ∏è 1 dedo ‚Üí Plano Entero
* ‚úåÔ∏è Paz ‚Üí Primer Plano
* ü§ò Rock ‚Üí Primer√≠simo Plano

**Lo que aprender√°s**: C√≥mo combinar detecci√≥n de pose y manos para crear interfaces de control gestual intuitivas.

![Bloque 3 - Control Manual](./gif3.gif)

---

### üî∑ Bloque 4: Encuadre Inteligente y Seguimiento Suave

**Objetivo**: Implementar el sistema de zoom din√°mico y seguimiento cinematogr√°fico del sujeto.

**Componentes**:
* Clase `SmoothFramer` con **interpolaci√≥n progresiva** (smoothing factor 0.15)
* C√°lculo de **centro de seguimiento adaptativo**:
  * Rostro para primeros planos
  * Torso superior para planos medios
  * Cuerpo completo para planos generales
* **Crop din√°mico** con factores de zoom de 0.7x a 2.8x
* **Offset vertical** personalizado por tipo de plano
* Dos ventanas simult√°neas:
  * DETECCI√ìN (con landmarks visibles)
  * RESULTADO (encuadre final cinematogr√°fico)

**Lo que aprender√°s**: T√©cnicas de crop din√°mico, interpolaci√≥n suave para evitar jitter, y c√≥mo calcular centros de inter√©s seg√∫n el contexto narrativo.

![Bloque 4 - Encuadre Inteligente](./gif4.gif)

---

## Limitaciones actuales

* El sistema est√° optimizado para **una persona principal**
* La detecci√≥n multi-persona no est√° completamente integrada
* Las decisiones son heur√≠sticas, no aprendidas

---

## Posibles ampliaciones y trabajo futuro

* **Detecci√≥n y seguimiento de m√∫ltiples personas**
  Se ha implementado una **base experimental** que funciona parcialmente en **modo AUTO**, pero:

  * no selecciona de forma robusta al sujeto principal
  * no gestiona correctamente cruces o solapamientos
  * no est√° integrada en modo MANUAL

* Entrenamiento de un modelo espec√≠fico para clasificaci√≥n de planos

* Selecci√≥n autom√°tica del ‚Äúpersonaje principal‚Äù

* Integraci√≥n con c√°maras PTZ reales

* Aprendizaje de estilos de direcci√≥n personalizados

* Exportaci√≥n directa a software de edici√≥n

---

## Conclusi√≥n

Este trabajo final demuestra que es posible traducir informaci√≥n corporal en **decisiones narrativas de c√°mara**, sin necesidad de modelos entrenados espec√≠ficamente para cine.

**El sistema autom√°tico de c√°mara inteligente** no sustituye al director, sino que propone una nueva categor√≠a:
 **herramientas audiovisuales inteligentes con criterio cinematogr√°fico**.

## Enlace a la demo

 [![Ver demo](https://img.youtube.com/vi/dWNdu7A24tk/0.jpg)](https://youtu.be/dWNdu7A24tk)

## Enlace al video promocional

[![Ver v√≠deo promocional](https://img.youtube.com/vi/42CfiugmXT8/0.jpg)](https://youtu.be/42CfiugmXT8)

