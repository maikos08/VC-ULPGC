{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33751dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presiona 'q' para salir\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Inicializar MediaPipe Pose y Hands\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# Configurar detectores\n",
    "pose = mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    model_complexity=1  # 0=ligero, 1=medio, 2=pesado\n",
    ")\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    max_num_hands=2\n",
    ")\n",
    "\n",
    "# Captura de video\n",
    "cap = cv2.VideoCapture(0)  # 0 = webcam por defecto\n",
    "\n",
    "print(\"Presiona 'q' para salir\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convertir BGR a RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Detectar pose y manos\n",
    "    pose_results = pose.process(image)\n",
    "    hands_results = hands.process(image)\n",
    "    \n",
    "    # Volver a BGR para dibujar\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Dibujar landmarks de pose\n",
    "    if pose_results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            pose_results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "    \n",
    "    # Dibujar landmarks de manos\n",
    "    if hands_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hands_results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style()\n",
    "            )\n",
    "    \n",
    "    # Mostrar FPS\n",
    "    cv2.putText(image, f'FPS: {int(cap.get(cv2.CAP_PROP_FPS))}', \n",
    "                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('MediaPipe Pose + Hands', image)\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pose.close()\n",
    "hands.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7375cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de landmarks de pose: [{'x': 0.6356474757194519, 'y': 0.5357095003128052, 'z': -1.2878602743148804, 'visibility': 0.9997855424880981}, {'x': 0.653036892414093, 'y': 0.45773619413375854, 'z': -1.1983544826507568, 'visibility': 0.9996163845062256}, {'x': 0.6700222492218018, 'y': 0.45641347765922546, 'z': -1.1983556747436523, 'visibility': 0.9996852874755859}]\n",
      "Ejemplo de landmarks de manos: None\n"
     ]
    }
   ],
   "source": [
    "def extract_pose_data(pose_landmarks):\n",
    "    \"\"\"Extrae coordenadas de landmarks de pose\"\"\"\n",
    "    if not pose_landmarks:\n",
    "        return None\n",
    "    \n",
    "    landmarks = []\n",
    "    for landmark in pose_landmarks.landmark:\n",
    "        landmarks.append({\n",
    "            'x': landmark.x,\n",
    "            'y': landmark.y,\n",
    "            'z': landmark.z,\n",
    "            'visibility': landmark.visibility\n",
    "        })\n",
    "    return landmarks\n",
    "\n",
    "def extract_hand_data(hands_results):\n",
    "    \"\"\"Extrae coordenadas y clasificaci贸n de manos\"\"\"\n",
    "    if not hands_results.multi_hand_landmarks:\n",
    "        return None\n",
    "    \n",
    "    hands_data = []\n",
    "    for idx, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "        hand_info = {\n",
    "            'handedness': hands_results.multi_handedness[idx].classification[0].label,  # \"Left\" o \"Right\"\n",
    "            'score': hands_results.multi_handedness[idx].classification[0].score,\n",
    "            'landmarks': []\n",
    "        }\n",
    "        \n",
    "        for landmark in hand_landmarks.landmark:\n",
    "            hand_info['landmarks'].append({\n",
    "                'x': landmark.x,\n",
    "                'y': landmark.y,\n",
    "                'z': landmark.z\n",
    "            })\n",
    "        \n",
    "        hands_data.append(hand_info)\n",
    "    \n",
    "    return hands_data\n",
    "\n",
    "# Testing extracci贸n\n",
    "print(\"Ejemplo de landmarks de pose:\", extract_pose_data(pose_results.pose_landmarks)[:3])\n",
    "print(\"Ejemplo de landmarks de manos:\", extract_hand_data(hands_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eed757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sistema de C谩mara Inteligente\n",
      "Controles:\n",
      "  ESC - Salir\n",
      "  'r' - Reset encuadre\n",
      "\n",
      "Gestos:\n",
      "  Pu帽o (0 dedos) -> Plano General\n",
      "  1 dedo -> Plano Medio\n",
      "  2 dedos (paz) -> Primer Plano\n",
      "  3+ dedos -> Plano Detalle\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "\n",
    "# ==================== INICIALIZACIN MEDIAPIPE ====================\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_face = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# Configuraci贸n de detectores\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.6,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "face_detection = mp_face.FaceDetection(\n",
    "    min_detection_confidence=0.6\n",
    ")\n",
    "\n",
    "# ==================== SISTEMA DE PLANOS ====================\n",
    "PLANOS = {\n",
    "    'PLANO_GENERAL': {'zoom': 1.0, 'nombre': 'Plano General'},\n",
    "    'PLANO_MEDIO': {'zoom': 1.5, 'nombre': 'Plano Medio'},\n",
    "    'PRIMER_PLANO': {'zoom': 2.0, 'nombre': 'Primer Plano'},\n",
    "    'PLANO_DETALLE': {'zoom': 2.5, 'nombre': 'Plano Detalle'}\n",
    "}\n",
    "\n",
    "# ==================== DETECCIN DE GESTOS ====================\n",
    "def contar_dedos(hand_landmarks):\n",
    "    \"\"\"Cuenta dedos levantados\"\"\"\n",
    "    dedos = 0\n",
    "    tips_ids = [4, 8, 12, 16, 20]\n",
    "    \n",
    "    # Pulgar (comparaci贸n horizontal seg煤n lado de la mano)\n",
    "    if hand_landmarks.landmark[tips_ids[0]].x < hand_landmarks.landmark[tips_ids[0] - 1].x:\n",
    "        dedos += 1\n",
    "    \n",
    "    # Otros dedos (comparaci贸n vertical)\n",
    "    for i in range(1, 5):\n",
    "        if hand_landmarks.landmark[tips_ids[i]].y < hand_landmarks.landmark[tips_ids[i] - 2].y:\n",
    "            dedos += 1\n",
    "    \n",
    "    return dedos\n",
    "\n",
    "def detectar_gesto_pu帽o(hand_landmarks):\n",
    "    \"\"\"Detecta pu帽o cerrado\"\"\"\n",
    "    return contar_dedos(hand_landmarks) == 0\n",
    "\n",
    "def detectar_gesto_paz(hand_landmarks):\n",
    "    \"\"\"Detecta gesto de paz (V)\"\"\"\n",
    "    indice_up = hand_landmarks.landmark[8].y < hand_landmarks.landmark[6].y\n",
    "    medio_up = hand_landmarks.landmark[12].y < hand_landmarks.landmark[10].y\n",
    "    anular_down = hand_landmarks.landmark[16].y > hand_landmarks.landmark[14].y\n",
    "    me帽ique_down = hand_landmarks.landmark[20].y > hand_landmarks.landmark[18].y\n",
    "    \n",
    "    return indice_up and medio_up and anular_down and me帽ique_down\n",
    "\n",
    "def clasificar_gesto(hand_landmarks):\n",
    "    \"\"\"Clasifica gesto y retorna plano correspondiente\"\"\"\n",
    "    dedos = contar_dedos(hand_landmarks)\n",
    "    \n",
    "    if detectar_gesto_pu帽o(hand_landmarks):\n",
    "        return 'PLANO_GENERAL', dedos\n",
    "    elif dedos == 1:\n",
    "        return 'PLANO_MEDIO', dedos\n",
    "    elif detectar_gesto_paz(hand_landmarks) or dedos == 2:\n",
    "        return 'PRIMER_PLANO', dedos\n",
    "    elif dedos >= 3:\n",
    "        return 'PLANO_DETALLE', dedos\n",
    "    else:\n",
    "        return 'PLANO_GENERAL', dedos\n",
    "\n",
    "# ==================== ORIENTACIN CORPORAL ====================\n",
    "class BodyOrientation:\n",
    "    \"\"\"Calcula orientaci贸n corporal 3D desde pose landmarks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.history = deque(maxlen=8)\n",
    "    \n",
    "    def calculate(self, pose_landmarks):\n",
    "        \"\"\"Calcula yaw, pitch, roll del cuerpo\"\"\"\n",
    "        if not pose_landmarks:\n",
    "            return None\n",
    "        \n",
    "        lm = pose_landmarks.landmark\n",
    "        \n",
    "        # Puntos clave para orientaci贸n\n",
    "        left_shoulder = np.array([lm[11].x, lm[11].y, lm[11].z])\n",
    "        right_shoulder = np.array([lm[12].x, lm[12].y, lm[12].z])\n",
    "        left_hip = np.array([lm[23].x, lm[23].y, lm[23].z])\n",
    "        right_hip = np.array([lm[24].x, lm[24].y, lm[24].z])\n",
    "        \n",
    "        # Vector de hombros (yaw - rotaci贸n horizontal)\n",
    "        shoulder_vec = right_shoulder - left_shoulder\n",
    "        yaw = np.arctan2(shoulder_vec[2], shoulder_vec[0]) * 180 / np.pi\n",
    "        \n",
    "        # Inclinaci贸n lateral (roll)\n",
    "        roll = np.arctan2(shoulder_vec[1], shoulder_vec[0]) * 180 / np.pi\n",
    "        \n",
    "        # Inclinaci贸n adelante/atr谩s (pitch)\n",
    "        torso_center = (left_shoulder + right_shoulder) / 2\n",
    "        hip_center = (left_hip + right_hip) / 2\n",
    "        torso_vec = torso_center - hip_center\n",
    "        pitch = np.arctan2(torso_vec[2], torso_vec[1]) * 180 / np.pi\n",
    "        \n",
    "        orientation = {\n",
    "            'yaw': yaw,\n",
    "            'pitch': pitch,\n",
    "            'roll': roll,\n",
    "            'visibility': min(lm[11].visibility, lm[12].visibility)\n",
    "        }\n",
    "        \n",
    "        self.history.append(orientation)\n",
    "        return self._smooth()\n",
    "    \n",
    "    def _smooth(self):\n",
    "        \"\"\"Suavizado temporal\"\"\"\n",
    "        if not self.history:\n",
    "            return None\n",
    "        return {\n",
    "            'yaw': np.mean([o['yaw'] for o in self.history]),\n",
    "            'pitch': np.mean([o['pitch'] for o in self.history]),\n",
    "            'roll': np.mean([o['roll'] for o in self.history]),\n",
    "            'visibility': np.mean([o['visibility'] for o in self.history])\n",
    "        }\n",
    "\n",
    "# ==================== SEGUIMIENTO Y ENCUADRE ====================\n",
    "@dataclass\n",
    "class FrameTarget:\n",
    "    \"\"\"Target de encuadre con transici贸n suave\"\"\"\n",
    "    x: float = 0.5\n",
    "    y: float = 0.5\n",
    "    zoom: float = 1.0\n",
    "\n",
    "class SmoothFramer:\n",
    "    \"\"\"Sistema de encuadre con transiciones suaves\"\"\"\n",
    "    def __init__(self, smoothing=0.12):\n",
    "        self.current = FrameTarget()\n",
    "        self.target = FrameTarget()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def update(self, center_x, center_y, zoom):\n",
    "        \"\"\"Actualiza target y suaviza transici贸n\"\"\"\n",
    "        self.target.x = center_x\n",
    "        self.target.y = center_y\n",
    "        self.target.zoom = zoom\n",
    "        \n",
    "        # Interpolaci贸n suave\n",
    "        self.current.x += (self.target.x - self.current.x) * self.smoothing\n",
    "        self.current.y += (self.target.y - self.current.y) * self.smoothing\n",
    "        self.current.zoom += (self.target.zoom - self.current.zoom) * self.smoothing\n",
    "        \n",
    "        return self.current\n",
    "\n",
    "def obtener_centro_seguimiento(pose_landmarks, face_result, w, h):\n",
    "    \"\"\"\n",
    "    Obtiene punto de seguimiento inteligente:\n",
    "    1. Cara si est谩 disponible\n",
    "    2. Punto medio entre nariz y hombros\n",
    "    3. Centro del frame\n",
    "    \"\"\"\n",
    "    # Prioridad 1: Cara detectada\n",
    "    if face_result and face_result.detections:\n",
    "        bbox = face_result.detections[0].location_data.relative_bounding_box\n",
    "        cx = bbox.xmin + bbox.width / 2\n",
    "        cy = bbox.ymin + bbox.height / 2\n",
    "        return (cx, cy)\n",
    "    \n",
    "    # Prioridad 2: Pose landmarks (cabeza/torso superior)\n",
    "    if pose_landmarks:\n",
    "        lm = pose_landmarks.landmark\n",
    "        # Promedio de nariz y punto medio de hombros\n",
    "        nose = np.array([lm[0].x, lm[0].y])\n",
    "        shoulders = (np.array([lm[11].x, lm[11].y]) + np.array([lm[12].x, lm[12].y])) / 2\n",
    "        center = (nose + shoulders) / 2\n",
    "        return (float(center[0]), float(center[1]))\n",
    "    \n",
    "    # Default: centro del frame\n",
    "    return (0.5, 0.5)\n",
    "\n",
    "def aplicar_encuadre(frame, framer_state):\n",
    "    \"\"\"\n",
    "    Aplica zoom y reencuadre DESPUS de dibujar landmarks\n",
    "    Esto soluciona el problema de landmarks desalineados\n",
    "    \"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    # Calcular regi贸n de inter茅s\n",
    "    zoom = framer_state.zoom\n",
    "    crop_w = int(w / zoom)\n",
    "    crop_h = int(h / zoom)\n",
    "    \n",
    "    # Centro normalizado -> p铆xeles\n",
    "    center_x = int(framer_state.x * w)\n",
    "    center_y = int(framer_state.y * h)\n",
    "    \n",
    "    # Calcular l铆mites del crop\n",
    "    x1 = max(0, center_x - crop_w // 2)\n",
    "    y1 = max(0, center_y - crop_h // 2)\n",
    "    x2 = min(w, x1 + crop_w)\n",
    "    y2 = min(h, y1 + crop_h)\n",
    "    \n",
    "    # Ajustar si sale de l铆mites\n",
    "    if x2 - x1 < crop_w:\n",
    "        x1 = max(0, x2 - crop_w)\n",
    "    if y2 - y1 < crop_h:\n",
    "        y1 = max(0, y2 - crop_h)\n",
    "    \n",
    "    # Crop y resize\n",
    "    cropped = frame[y1:y2, x1:x2]\n",
    "    if cropped.size == 0:  # Validaci贸n\n",
    "        return frame\n",
    "    \n",
    "    resized = cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "\n",
    "# ==================== VISUALIZACIN ====================\n",
    "def dibujar_landmarks(frame, pose_results, hands_results, face_results):\n",
    "    \"\"\"\n",
    "    Dibuja todos los landmarks EN EL FRAME ORIGINAL\n",
    "    Esto es CRTICO para evitar desalineaci贸n\n",
    "    \"\"\"\n",
    "    # Dibujar pose\n",
    "    if pose_results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            pose_results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "    \n",
    "    # Dibujar manos\n",
    "    if hands_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hands_results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style()\n",
    "            )\n",
    "    \n",
    "    # Dibujar cara\n",
    "    if face_results.detections:\n",
    "        for detection in face_results.detections:\n",
    "            mp_drawing.draw_detection(frame, detection)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def dibujar_info_deteccion(frame, num_dedos, plano, orientation):\n",
    "    \"\"\"Dibuja info en frame de detecci贸n (izquierdo)\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    y_offset = 30\n",
    "    \n",
    "    # Dedos detectados\n",
    "    if num_dedos is not None:\n",
    "        cv2.putText(frame, f\"Dedos: {num_dedos}\", (10, y_offset),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        y_offset += 35\n",
    "    \n",
    "    # Plano actual\n",
    "    cv2.putText(frame, f\"Plano: {PLANOS[plano]['nombre']}\", (10, y_offset),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "    y_offset += 35\n",
    "    \n",
    "    # Orientaci贸n corporal\n",
    "    if orientation and orientation['visibility'] > 0.5:\n",
    "        cv2.putText(frame, f\"Yaw: {orientation['yaw']:.1f}掳\", (10, y_offset),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 200, 100), 2)\n",
    "        y_offset += 28\n",
    "        cv2.putText(frame, f\"Pitch: {orientation['pitch']:.1f}掳\", (10, y_offset),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 200, 100), 2)\n",
    "        y_offset += 28\n",
    "        cv2.putText(frame, f\"Roll: {orientation['roll']:.1f}掳\", (10, y_offset),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 200, 100), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def dibujar_info_principal(frame, plano, fps):\n",
    "    \"\"\"Dibuja info en frame principal (derecho)\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    # Nombre del plano (abajo a la izquierda)\n",
    "    cv2.putText(frame, PLANOS[plano]['nombre'], (10, h - 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "    \n",
    "    # FPS (arriba a la derecha)\n",
    "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (w - 150, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # Regla de tercios (grid)\n",
    "    color_grid = (80, 80, 80)\n",
    "    cv2.line(frame, (w//3, 0), (w//3, h), color_grid, 1)\n",
    "    cv2.line(frame, (2*w//3, 0), (2*w//3, h), color_grid, 1)\n",
    "    cv2.line(frame, (0, h//3), (w, h//3), color_grid, 1)\n",
    "    cv2.line(frame, (0, 2*h//3), (w, 2*h//3), color_grid, 1)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def crear_pantalla_dividida(frame_principal, frame_deteccion):\n",
    "    \"\"\"Crea pantalla dividida horizontal\"\"\"\n",
    "    h, w = frame_principal.shape[:2]\n",
    "    \n",
    "    # Redimensionar ambos frames\n",
    "    frame_det_small = cv2.resize(frame_deteccion, (w // 2, h))\n",
    "    frame_prin_small = cv2.resize(frame_principal, (w // 2, h))\n",
    "    \n",
    "    # Concatenar horizontalmente: detecci贸n | principal\n",
    "    split_screen = np.hstack((frame_det_small, frame_prin_small))\n",
    "    \n",
    "    return split_screen\n",
    "\n",
    "# ==================== MAIN ====================\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Configurar resoluci贸n\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    # Sistemas\n",
    "    orientation_tracker = BodyOrientation()\n",
    "    framer = SmoothFramer(smoothing=0.12)\n",
    "    fps_history = deque(maxlen=30)\n",
    "    \n",
    "    # Estado\n",
    "    plano_actual = 'PLANO_GENERAL'\n",
    "    num_dedos = None\n",
    "    \n",
    "    print(\" Sistema de C谩mara Inteligente\")\n",
    "    print(\"Controles:\")\n",
    "    print(\"  ESC - Salir\")\n",
    "    print(\"  'r' - Reset encuadre\")\n",
    "    print(\"\\nGestos:\")\n",
    "    print(\"  Pu帽o (0 dedos) -> Plano General\")\n",
    "    print(\"  1 dedo -> Plano Medio\")\n",
    "    print(\"  2 dedos (paz) -> Primer Plano\")\n",
    "    print(\"  3+ dedos -> Plano Detalle\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Voltear para efecto espejo\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Convertir a RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # ===== PROCESAR DETECCIONES =====\n",
    "        pose_results = pose.process(rgb_frame)\n",
    "        hands_results = hands.process(rgb_frame)\n",
    "        face_results = face_detection.process(rgb_frame)\n",
    "        \n",
    "        # ===== FRAME DE DETECCIN (con landmarks) =====\n",
    "        frame_deteccion = frame.copy()\n",
    "        frame_deteccion = dibujar_landmarks(\n",
    "            frame_deteccion, pose_results, hands_results, face_results\n",
    "        )\n",
    "        \n",
    "        # ===== ANALIZAR GESTOS Y ORIENTACIN =====\n",
    "        # Gestos de mano\n",
    "        if hands_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hands_results.multi_hand_landmarks:\n",
    "                plano_detectado, num_dedos = clasificar_gesto(hand_landmarks)\n",
    "                plano_actual = plano_detectado\n",
    "        \n",
    "        # Orientaci贸n corporal\n",
    "        orientation = orientation_tracker.calculate(pose_results.pose_landmarks)\n",
    "        \n",
    "        # ===== CALCULAR ENCUADRE =====\n",
    "        centro = obtener_centro_seguimiento(pose_results.pose_landmarks, face_results, w, h)\n",
    "        zoom_factor = PLANOS[plano_actual]['zoom']\n",
    "        framer_state = framer.update(centro[0], centro[1], zoom_factor)\n",
    "        \n",
    "        # ===== FRAME PRINCIPAL (aplicar encuadre) =====\n",
    "        # IMPORTANTE: Dibujar landmarks ANTES de aplicar zoom/crop\n",
    "        frame_principal = frame.copy()\n",
    "        frame_principal = dibujar_landmarks(\n",
    "            frame_principal, pose_results, hands_results, face_results\n",
    "        )\n",
    "        # Ahora s铆 aplicar encuadre\n",
    "        frame_principal = aplicar_encuadre(frame_principal, framer_state)\n",
    "        \n",
    "        # ===== DIBUJAR INFO =====\n",
    "        frame_deteccion = dibujar_info_deteccion(\n",
    "            frame_deteccion, num_dedos, plano_actual, orientation\n",
    "        )\n",
    "        \n",
    "        fps = 1.0 / (time.time() - start_time)\n",
    "        fps_history.append(fps)\n",
    "        avg_fps = np.mean(fps_history)\n",
    "        \n",
    "        frame_principal = dibujar_info_principal(frame_principal, plano_actual, avg_fps)\n",
    "        \n",
    "        # ===== PANTALLA DIVIDIDA =====\n",
    "        pantalla_final = crear_pantalla_dividida(frame_principal, frame_deteccion)\n",
    "        \n",
    "        # ===== MOSTRAR =====\n",
    "        cv2.imshow('Sistema de C谩mara Inteligente | Detecci贸n + Resultado', pantalla_final)\n",
    "        \n",
    "        # ===== CONTROLES =====\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "        elif key == ord('r'):\n",
    "            framer = SmoothFramer(smoothing=0.12)\n",
    "            print(\" Encuadre reseteado\")\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pose.close()\n",
    "    hands.close()\n",
    "    face_detection.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camera_intelligent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
